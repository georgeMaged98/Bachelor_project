{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22439ca",
   "metadata": {},
   "source": [
    "### Basic Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07bad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322d04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_DB1(subject,exercise):\n",
    "    data = loadmat(f'../Dataset/DB1/s{subject}/S{subject}_A1_E{exercise}.mat')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f296d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_indexes(data,movement,target):\n",
    "    start_indexes=[]\n",
    "    for idx,move in enumerate(data[target]):\n",
    "        if move[0] == movement and data[target][idx-1][0] == 0:\n",
    "            start_indexes.append(idx)\n",
    "        if len(start_indexes) == 10:\n",
    "            break\n",
    "    return start_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3daf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movement_df(data,movement,target):\n",
    "    '''\n",
    "    Returns the repetitions of a movement based on fixed length of repetition.\n",
    "    if target is stimulus then each rep takes 5 seconds but if target is restimulus then each rep takes 2 seconds\n",
    "    '''\n",
    "    start_indexes = get_start_indexes(data,movement,target)\n",
    "    df= pd.DataFrame()\n",
    "    step = 500 if target == 'stimulus' else 200\n",
    "    for i in start_indexes:\n",
    "        new_row = data['emg'][i:i+step].flatten()\n",
    "        df = df.append(pd.Series(new_row),ignore_index=True)\n",
    "    target_movement = np.full((10,1),movement,dtype=int)\n",
    "    df['target_movement'] = target_movement\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae490e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_repetitions(data, movement):\n",
    "    '''\n",
    "    Returns a dataframe with the 10 repetitions of a movement  based on restimulus.\n",
    "    The returned dataframe considers the varying length of each repetition.\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    restimulus_indices = get_start_indexes(data=data, movement=movement, target=\"restimulus\")\n",
    "    for i in restimulus_indices:\n",
    "        j = i\n",
    "        while data[\"restimulus\"][j] == movement:\n",
    "            j+=1\n",
    "        repetition_df = pd.DataFrame(data[\"emg\"][i:j].flatten().reshape(1,len(data[\"emg\"][i:j].flatten())))\n",
    "        repetition_df[\"target\"] = movement\n",
    "        df = df.append(repetition_df, ignore_index=True)\n",
    "\n",
    "    col_names = list(range(0,df.shape[1] - 1))\n",
    "    col_names.append(\"target\")\n",
    "    df = df.reindex(columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c705c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import math\n",
    "\n",
    "def interpolate_dataframe(df):\n",
    "    '''\n",
    "    Takes a dataframe with NaN and returns an interpolated version of the dataframe with no NaNs.\n",
    "    '''\n",
    "    data = df.drop(\"target\", axis=1)\n",
    "    target_col = df[\"target\"]\n",
    "    \n",
    "    max_row_length = data.shape[1]\n",
    "    max_range = list(range(0, max_row_length))\n",
    "    for idx,row in data.iterrows():\n",
    "        current_row_length = len(row.dropna())\n",
    "        current_range = list(range(0, current_row_length))\n",
    "        new_row = pd.Series(index=max_range, dtype='float64')\n",
    "        for i in current_range:\n",
    "            j = math.ceil(i * max_row_length / current_row_length)\n",
    "            new_row.iloc[j] = row.iloc[i]\n",
    "        \n",
    "        new_row.interpolate(method=\"linear\",inplace=True)\n",
    "        data.iloc[idx] = new_row\n",
    "    data[\"target\"] = target_col\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a439524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import math\n",
    "\n",
    "def interpolate_dataframe_with_length(df, max_length):\n",
    "    '''\n",
    "    Takes a dataframe and a desired length for data (ignoring target column) with NaN and returns an interpolated version of the dataframe with no NaNs.\n",
    "    '''\n",
    "    data = df.drop(\"target\", axis=1)\n",
    "    target_col = df[\"target\"]\n",
    "    \n",
    "    max_row_length = max_length\n",
    "    max_range = list(range(0, max_row_length))\n",
    "    \n",
    "    # Creating datafram to hold new data with new length\n",
    "    new_data = pd.DataFrame(columns=max_range)\n",
    "\n",
    "        \n",
    "    for idx,row in data.iterrows():\n",
    "        current_row_length = len(row.dropna())\n",
    "        current_range = list(range(0, current_row_length))\n",
    "        new_row = pd.Series(index=max_range, dtype='float64')\n",
    "        for i in current_range:\n",
    "            j = math.ceil(i * max_row_length / current_row_length)\n",
    "            new_row.iloc[j] = row.iloc[i]\n",
    "        \n",
    "        new_row.interpolate(method=\"linear\",inplace=True)\n",
    "        new_data = new_data.append(new_row, ignore_index=True)\n",
    "    new_data[\"target\"] = target_col\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e9456",
   "metadata": {},
   "source": [
    "# Visualizing signals before and after interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "501b9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data of exercise 1 for subject 1\n",
    "sub1_ex1 = load_data_DB1(subject=1, exercise=1)\n",
    "\n",
    "# Get resimulus indexes for movement 1\n",
    "restimulus_idxs_move1 = get_start_indexes(data=sub1_ex1, movement=1, target=\"restimulus\")\n",
    "\n",
    "# Concatenating every repetition of movement 1 in exercise 1 based on how long it takes and not fixed size\n",
    "move1_df = pd.DataFrame()\n",
    "for i in restimulus_idxs_move1:\n",
    "    j = i\n",
    "    while sub1_ex1[\"restimulus\"][j] == 1:\n",
    "        j+=1\n",
    "    rep_df = pd.DataFrame(sub1_ex1[\"emg\"][i:j].flatten().reshape(1,len(sub1_ex1[\"emg\"][i:j].flatten())))\n",
    "    rep_df[\"target\"] = 1\n",
    "    move1_df = move1_df.append(rep_df, ignore_index=True)\n",
    "\n",
    "col_names = list(range(0,move1_df.shape[1]-1))\n",
    "col_names.append(\"target\")\n",
    "move1_df = move1_df.reindex(columns=col_names)\n",
    "len(move1_df.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ac267847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAEvCAYAAADSGNH4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABTp0lEQVR4nO3deZxbV3n/8e+ZxY6TkIQlUEqgTiEU0gJtSQNlKYEGmgBtoHQJlEChNL8AaWmBgglJIAvZnIRszr4Tsji7E2/xvm/jZTzePbbHnvHYs9iz75LO7w9pZjQaaXQlXele6X7er1deGd250n08V8uj557zHGOtFQAAAAAAAEpbmdcBAAAAAAAAIP8oAgEAAAAAAAQARSAAAAAAAIAAoAgEAAAAAAAQABSBAAAAAAAAAoAiEAAAAAAAQABUeHXgt73tbXbq1KleHR4AAOTZxo0bW621p3sdB8YiBwMAoLRNlIN5VgSaOnWqqqqqvDo8AADIM2PMQa9jwHjkYAAAlLaJcjCmgwEAAAAAAAQARSAAAAAAAIAAoAgEAAAAAAAQABSBAAAAAAAAAoAiEAAAAAAAQABQBAIAAAAAAAgAikAAAAAAAAABQBEIAAAAAAAgACgCAQAAAAAABABFICADB4/1qK61x+swAAAAAmXzoTZ19g95HQYAFD2KQEAGPjN9qc67danXYQAAAATGUDiir967Wt99bIPXoQBA0aMIBAAAAMC3ItZKkrY2dHgcCQAUP4pAAAAAAAAAAeCoCGSMucAYs9sYU2uMmZZin/OMMVuMMduNMcvcDRMAACB4yMEAAICbKtLtYIwplzRD0uclNUjaYIyZZa3dEbfPaZLulXSBtfaQMebteYoXAAAgEMjBgLGsrNchAEDRczIS6FxJtdba/dbaQUnPSrooYZ9vSHrJWntIkqy1ze6GCQAAEDjkYIAkI+N1CABQMpwUgd4lqT7udkNsW7z3S3qzMWapMWajMeZbyR7IGHOpMabKGFPV0tKSXcQAAADBQA4GAABc5aQIlKz0njgWs0LSRyV9SdLfSbrKGPP+cXey9kFr7TnW2nNOP/30jIMFAAAIEHIwAADgqrQ9gRS96vTuuNtnSGpMsk+rtbZHUo8xZrmkj0ja40qUgA+srm31OgQAQLCQgwGSnquqT78TAMARJyOBNkg6yxhzpjFmkqSLJc1K2OdVSZ82xlQYY06U9DFJO90NFfDWNx5e53UIAIBgIQdD4B1u79NVr2zzOgwAKBlpRwJZa0PGmMslzZdULulRa+12Y8xlsd/fb63daYyZJ2mrpIikh621vFsDAABkiRwMkELhiNchAEBJcTIdTNbaOZLmJGy7P+H2dEnT3QsNAAAg2MjBAACAm5xMBwMAAAAAAECRowgEAAAAwPds4tp4AICMUQQCAAAA4EtGxusQAKCkUAQCAAAAAAAIAIpAAAAAAAAAAUARCMjCS5savA4BAAAgUEIRq60N7V6HAQBFjSIQkIUfz6z2OgQAAIDA+Yd7VnkdAgAUNYpAAAAAAAAAAUARCAAAAAAAIAAoAgEAAAAAAAQARSAAAAAAvmSM1xEAQGmhCAQAAAAAABAAFIEAAAAAAAACgCIQAAAAAABAAFAEAgAAAAAACACKQAAAAAAAAAFAEQgAAAAAACAAKAIBAAAAAAAEAEUgAAAAAACAAKAIBAAAAAAAEAAUgQAAAAAAAAKAIhAAAAAAAEAAUAQCAAAAAAAIAIpAAAAAAAAAAUARCAAAAAAAIAAoAgEAAAAAAAQARSAAAAAAAIAAoAgEAAAAwJeM8ToCACgtFIEAAAAAAAACgCIQAAAAAABAAFAEAgAAAAAACABHRSBjzAXGmN3GmFpjzLQkvz/PGNNhjNkS++9q90MFAAAIFnIwAADgpop0OxhjyiXNkPR5SQ2SNhhjZllrdyTsusJa++U8xAgAABA45GAAAMBtTkYCnSup1lq731o7KOlZSRflNyzA/wZCYa9DAACUNnIwIIlwxHodAgAULSdFoHdJqo+73RDbluivjTHVxpi5xpg/dSU6wMf+5Mp5XocAACht5GBAEv/+2HqvQwCAopV2Opgkk2RbYvl9k6Q/stZ2G2O+KOkVSWeNeyBjLpV0qSS95z3vySxSAACAYCEHA5JYsbfV6xAAoGg5GQnUIOndcbfPkNQYv4O1ttNa2x37eY6kSmPM2xIfyFr7oLX2HGvtOaeffnoOYQMAAJQ8cjAEnjHJaqEAgGw5KQJtkHSWMeZMY8wkSRdLmhW/gzHmD0zsHdoYc27scY+5HSwAAECAkIMBAABXpZ0OZq0NGWMulzRfUrmkR621240xl8V+f7+kf5L0fWNMSFKfpIuttXRsAwAAyBI5GAAAcJuTnkDDw4vnJGy7P+7neyTd425oAAAAwUYOBgAA3ORkOhgAAAAAAACKHEUgAAAAAACAAKAIBAAAAAAAEAAUgQAAAAAAAAKAIhAAAAAAXzJeBwAAJYYiEAAAAAAAQABQBAIAAAAAAAgAikAAAAAAAAABQBEIAAAAAAAgACgCAQ7UNnd7HQIAAEDgbKg77nUIAFBSKAIBDpx/+zKvQwAAAAiUvU1d+tGzW7wOAwBKCkUgAAAAAL7T1jvkdQgAUHIoAgEAAAAAAAQARSAAAAAAAIAAoAgEAAAAwHeM8ToCACg9FIEAAAAAAAACgCIQAAAAAABAAFAEAgAAAAAACACKQAAAAAAAAAFAEQgAAAAAACAAKAIBAAAAAAAEAEUgAAAAAL7DCvEA4D6KQEAOXt1y2OsQAAAAAmdLfbvXIQBAUaIIBCTxu7UHdbSjP+1+P3p2S/6DAQAACICu/iE9sGyfIhGbdt+vzFhVgIgAoPRQBAISHO3o11WvbNN/PLHB61AAAAAC4zezd+rGubu0eFez16EAQMmiCAQkCEUikqT23iGPIwEAAAiOzv5o7jUQingcCQCULopAAAAAAAAAAUARCEjB2vTz0QEAAOAuq2gOZlgeDABcRxEISGDIOAAAAArOsCg8AOQdRSAAAAAAAIAAoAgExAlHrH716javwwAAAAiU+uO9ml1zxOswAKDkOSoCGWMuMMbsNsbUGmOmTbDfXxljwsaYf3IvRKBwttS3a+FOliUFAPgDORiC4sczt3gdAgAEQtoikDGmXNIMSRdKOlvS140xZ6fY72ZJ890OEgAAIGjIwRAkEdbjAICCcDIS6FxJtdba/dbaQUnPSrooyX7/JelFSQyjQElo7OjX1oZ2r8MAAAQXORgC6Sczq9UzEPI6DAAoSU6KQO+SVB93uyG2bYQx5l2SvirpfvdCAwovcWGwi2as8iYQAADIwRAg8SnYQCiiZ9YfStgKAHCDkyJQsnffxAGbd0j6ubU2POEDGXOpMabKGFPV0tLiMETAO6QeAAAPkYMBAABXVTjYp0HSu+NunyGpMWGfcyQ9a6LDKN4m6YvGmJC19pX4nay1D0p6UJLOOeccZv7C93iSAgA8RA4GAABc5aQItEHSWcaYMyUdlnSxpG/E72CtPXP4Z2PM45JeT0w+AAAAkBFyMAAA4Kq0RSBrbcgYc7miK06US3rUWrvdGHNZ7PfMQQcAAHAZORgAAHCbk5FAstbOkTQnYVvSxMNa+++5hwUAAAByMAAA4CYnjaGBwKARNAAAQOElrtCaahsAIDcUgQAAAAAAAAKAIhAwAcv6KQAAAAVnLXkYAOQDRSAAAAAAAIAAoAgEAAAAwHfoCQQA7qMIBAAAAAAAEAAUgYA4hktOAAAABWdYoxUACoIiEJCjqdNmex0CAABAyUlXFvrPJ6sKEgcAlBKKQAAAAAB8xSr90mALdjQVIBIAKC0UgQAAAAAAAAKAIhCQxs3zdnkdAgAAQKDcMGeXNh9q9zoMACg5FIGANO5bus/rEAAAAAJnTs0Rr0MAgJJDEQiIw7oUAAAAHiAJA4CCoAgE+NSrWw5r6rTZOtLR53UoAAAAgfEfj29g9VcAJYsiEOBTL2xskCTtaer2OBIAAIDgWLSr2esQACBvKAIBAAAAAAAEAEUgwIestQpH7MjPAAAAyL9IhLwLQGmjCATEMT5pSvjQiv1ave+Y12EAAAAUhE9SMF1w53KvQwCAvKIIBPjQixsPex0CAACAp7wYk0MvRgCljiIQAAAAAABAAFAEAgAAAOA7fpkiBgClhCIQ4EPxvYloTwgAAAAAcANFIAAAAAAAgACgCATEMT4ceHy0o9/rEAAAAPIq2QqtXo+GPt4z6HEEAOA+ikCAz/3ipRptPNjmdRgAAACB8pfXLfA6BABwHUUgoAjUNnd5HQIAAEBB1TazXDsAuI0iEAAAAADf6egb8joEACg5FIEAAAAAAAACgCIQ4AJrM29daK3V9saOPEQDAACAVHoGQqpr7fE6DADwBEUgIE6ylSnyZVZ1o75010rNrTlSuIMCAAD4UCFXaP3Wo+t13q1LC3Y8APATikBAnPUHjmd1v60NmY/o2dMUbfa8r4WmhwAAILj6BsOqbmjP6r71x3szvg+rrgIIMopAQExV3XFd+/qOrO570YxV6h8KZ3Xf9XVtikQyn04GAABQCn48c4t6B7PLoz59y5Ksj7vtMNPyAQSPoyKQMeYCY8xuY0ytMWZakt9fZIzZaozZYoypMsZ8yv1Qgfxq6hzI6f6hDAs5w8Oel+9p0WOr63I6NgCgNJGDIQiyGVHthi/fvTLri3gAUKwq0u1gjCmXNEPS5yU1SNpgjJllrY0fMrFI0ixrrTXGfFjSTEkfyEfAgF9l0xx62P6EKWGmkM2JAAC+RA4G5F8kh/wNAIqRk5FA50qqtdbut9YOSnpW0kXxO1hru+3oN+CTJPFuiqLjZd2FFwwAIAlyMCDPqAEBCBonRaB3SaqPu90Q2zaGMearxphdkmZL+m6yBzLGXBobqlzV0tKSTbxAUZm37agGQpkPM2YcEABA5GBAVjr7h7Rkd7PXYQCALzkpAiX7PjquZm6tfdla+wFJX5F0XbIHstY+aK09x1p7zumnn55RoEAx2dvUpd+tqdNlT23UTXN3Jd1nopFHXJQCAIgcDMjY6tpWffvR9frOYxt0pKPP63AAwHfS9gRS9KrTu+NunyGpMdXO1trlxpj3GmPeZq1tzTVAoFjEZ+Wf/+3ykZ8Pt5GAAACyQg4GZCAUjugbD68bud0/FPEwGgDwJycjgTZIOssYc6YxZpKkiyXNit/BGPM+E+tka4z5S0mTJB1zO1ggn/I1BcvJqJ7E+eiJsRgmiAFAEJGDIRDc6suYmHM5WbSD0dcAgiZtEchaG5J0uaT5knZKmmmt3W6MucwYc1lst69J2maM2aLoKhb/ap286wJw5PmN9QpnuAQ9gqGzf0ivVaccGACgiJGDAd5bsoveQkhuT1OXquqOex0GkDEn08FkrZ0jaU7Ctvvjfr5Z0s3uhgaUtrEXvSbO1zfUtemptQf17U9MzWNEKEY/fq5aC3c26YPvPEXve/vJXocDwGXkYEB+pauZfufxDaq76UsFigbF5Aux9g88P1BsnEwHA5BnM6sa1DsYmnCftt7BAkWDYtLYHu051T+U+Sp0AAAE3atbGE0LIFgoAgEuSXUhKeUFprgJ8OGI1TWzdmT1+AAAABjPSep05SvbVH+8N++xAIBfUAQCYtxqSrhmX3b9OFu7B1yPBaWP5woAoNi59Vn20qaGrO43GGYVMQDBQREIcNnXH1qb1f0Y6INMHeno0/bGTq/DAADAc02d/fr5izVZ3ZfR1sjUuv0swojiRREIyLOFO5t0vGd8P5/Ei15eLuYys6p+pLcMise/P7rB6xAAAPCFoSSjeZ5YXecwv/ImB+sbDOvhFfsVYQXYovOvD2Z30RfwA4pAgFsm+Pz+n+e2jLndMxDSvUtrx2xbsrtFLV0DSiVf6UFX/5B+9sJWffPhdXk6AvLlWM/o84WrmACAIDNJ5pQ9ueagNte3j9m2I8kI2geW7ffkYtxtb+zW9bN36rWtNKcGUDgUgYAR+Wuu0pYwEmj6/N0aCo9PNv77mc15iyGVSOzCWXxPIhSfOxft4UoiAKAomTzmYANDY0cIffGuFeP2eX5jg6oOtuUthlQ6+4ckscJnsXtl82GvQwAyQhEI8ED3QPLl4NfsP6b6471JGyTetWivelLcD6kNhSO6fcEe9Q6W4t9u9ImycGezlu1t8TAWAAC8k2sZafr83QqnuJjy2KoDOT56MB1o7dETq+u8DiPvEkf8A35HEQjwmUseST0t69Y3drt+PFvCLal7BkL6y2sX6K5Fe3XXotr0d8iT6vp2PbX2YN6PE04yugwAAKS3/sBxzak5kvR317y2I+UFvFyU8lTubYc79Nlbl+pXs7Yn7ddUKC9vbtDqfa2eHR/wI4pAgEvuXrzXlfnkXf2pk4z+IXc/RK21unuxd8WRfLt3aa26Ykmbl0OtL5qxSle+si3vxynhXBIAgJRmb01evMnUYKhwxYpj3QN6fmN2S9oXgy/fvdLrECRJ//tctb7xEH0vgXgUgYCYZFOwMvHwygM60NqT9HfujbZx92v+vpYePbKydIc4J+u7BAAA/CXXHOyHT29K+Rhu5WBuN46+4uXslrMvRqU84gkoRhSBABe50ZfXStp2ePzKFfkQiftU7uwPaXtjR0GOC3fkmjQDAIBRAwUcCRQ/uvu613eqb5Dm0AAKgyIQEGCJNYQv3eWPobtuoUYCAACcmllVX7BjxV/I6R4I6ZGV+wt2bADBRhEI8MBExYnjCcvJo7gt3d1csGO5PVQdAIBi4cYy81vq23MPJEshN4aTY4wHlu3zOgTAlygCAQWQ+N082495vuNnz6sCyb8/tmHk5//3uyq9Vt3oSRwAAASSSx//pGDZ82ol2hvn7hr5+f/9rkp7mro8iQPwG4pAgKLDcP/r6c0uPFJ+P+QW7mzS3Yv25vUYJSXuouATaw6qsb3Pu1gkzd/epP96xo3nGQAApWHzoTYdPNab8+Pku0/eXQv3auGOpvwepET94sUaRTwe6TR/e5MueYRVwgCJIhAgSXp2/SENhgvXDDDbPKW1e1C3LdgzZltDW69+PHNLVsuaBq2x8PWzd3gdAgAAiPPP96/xOgRHHl55QN97smrMtoU7mnTv0tqsHi9IKdhLmw/rsMcX4gCMoggEFEA+ZyL98uVtemnTYa3a15q/g5SIUppOt3pfq1q6BsZsK6F/HgAArsjnZ+P3nqzSLfN25/EIpaOUcjB6DaHYUQQCJJlSGBJThB+uy/e06D+frKKhcRa+8dD4Ic3/73cb1d5LY3EAQPFwKwUrgUyuoO5cuFczlmQ3iino4nsNDfvxzC2FDwTIEkUgwEWpahk7jnRqQ93xvBxzOHn6zuMb1NE3lJdj5Mt3H9+gBTuaMl4R4/Y3duuxVQfS7ufGSiHF5rWtR7wOAQAA3/i3h9epqz+/+dG0F7fm9fHz4bcL92j6/MxGMYXCEX3nsfXafKgtT1EVr5c2HfY6BMAxikBAgfzg95vy8rjxZY45NcVZAPin+1ZrKIOeTHctrtU1r9HfJylGVQEAMMainc15ffxnN9Tn9fHz6frXnedTB4/3asnuFv1kZnUeIwKQbxSBABdd9eq2lL/z23fz3sGQvjpj9bjtL29ucOXx//PJKs1NU5QaHsVU3dChps7+nI5nrdUlj6zT4l2pV+5IPAc/nrlFM6uKN3EDAABR/3jf+JxmmFdLlKey8WCbluxuGbPtjoV7dfBYT86P3dzZrwvvXKEjHc4aMT+8Mv3I6kSJf82Gtl598c4Vau0eSLp/9D6j9+rsH9Lf371Stc3dGR8bQO4oAgFybx752v3pp3xV17fr+Y3uFFqksf2MMik0bahrU9dAaNz2/30uu6s73QMhfe7WpSNDhBfsaNL3Mxj9lE2R7Nq40UChiNWKva269MmNju//0qbD+tkLW7Ne2cMtXf1DOm/6EtU0dHgaBwAAhebW1O2GtvRFjweX+6Oh7xUv1STdft/S7OJbf+C4zr99mfqHwnp2Q712HunU0+sO5RJiUsNn6kBrj+ZvPzqy/eEVB7TjSKdmbWl09DjLdreo5nCHzr99mTYe9HZq2eraVn3ht8s0EAp7GgdQSBSBgALLdP51Ml+ZsSqn+zd39evbj67POY541fXt2t/ao6/eu1pLduVv2PV3H98w8vOjSfoChSJWT609KMl5s8lCr+yROIx6Q91x1R3r1e0LWGEEAIB8uWHO+Ia+mbo1xzxubs0R7W7qyjmOeNe+vl21zd36wFXz1N6bn/5HXf1D+txty0Zu/8+zW5LEsUP7WjIb3XPT3J25huZYU+eAXto09kLsVa9u056mbtUf7y1YHIDXKAIBBePeUOQt9e2SpJV7W7U4i4JLPos0UrRJ9bBHsxhmPBEn/94rX0k9Lc8PXoxLQJq7+vXdx6skufMM8deAdwAAvOfmlPx7Yitq3TIvu4LSL15OPgrILcMXyO5eXKudRzpde9yaw2NHK6eaYvecg/5I8RfpCt0u4cdxF+Lm1hzRvpYeT+IAvEQRCIHzwsYG/dVvFioSW5Fqb1OXrs2gKZ6fXD/bP3GnGnTjp7+t33oCSNFpc0619w7qT66cq7X7j+UxIgAA8uNHz27Wj5/bMnL7sVUHNJjBwhB+cm+WU7fyIdWUukdcvhCXCz8WWX72gvNV3RbuaNKHfjVffYNMG0PxowiEwLnipRq1dA1oKBJNOtzsz1Mssp1/P7OqXp+8abHL0QTT2VfPU3vvYEb32VzfroFQJOueAQAAeOnVLY16afPoUtpBXOkz2w5I//XM5qJYit76sdqT4OIH12R8n5vn7VLXQEj1bUwbQ/GjCITAKoLPqLRMQtObK16uUW2zu/PM4/3sha063O5stQkn3GoGGX0sZ9ustfrQr+aP9A3ySu9gWJtj0/qGOX1OLtvTkvJ3pfC8BgDATYX4bPzL6xbk9fFfq2701VL08X9Tpz0YdzR2auq02ToU13/Hi7Ql2UIuTuP4wm+XuxsM4IEKrwMACumRleOHHbtXhii8ZLHPqj6iH3/+TXk9rrV2XAEqqz+ki3/8xA/vTYfaxg3Vnr+9SWf+Yo4k6epXfdA3KMPMp5ifqwCAYLvkkXVeh5BXx3syG91bbCa6cJdYZPvtgj3j9jnv1qUjPy/MYCq8XzgtdAHFgJFACJTrPOxPU7ARGk4OlOMH2Zm/mKP+IXfnRLv99/nHe1dPfDx3D5eV7zy+QY0ujqwCAMCvVuxt9ToEXxh3ES1DyaYy+alA8dCKA7pz0d4J9/FDDjZ12myuriGwKAIh8B5Yvt/rELLm5Ye+20uQ/s30JWor4FW0xKLTtx9dX7Bjx1tZS5NnAEDw9A6GvA6hKCWbypSrT92cW7/HTPPRzYfaR37eeLBNz6w/lNPxAWTGURHIGHOBMWa3MabWGDMtye//zRizNfbfamPMR9wPFcjOpU9W6cI7V4zb/oGr5nmSgPjpak0ucl1p6/Y3dmswNHZq3r6W7qweq28wrLN+OTeneCbqs1NMfjVru7YlLOMKoHiRg6GYTZ02W3csHD816Mt3r1BT54AHEUGS/i6hr01DW/pRyYn563AWuHJvqx5bVZdTPDOW1OZ0f7+YOm221yEAjqQtAhljyiXNkHShpLMlfd0Yc3bCbgckfcZa+2FJ10l60O1AgWy9saNJO490Jv1dS1fhEhAr6bkNhzwfDr3tcEdGS2I6NdFc8R8+vWnctrsWj//Az6as9De3LFFrd2kkksv2tGhmVe5NH+dvP+pCNAC8Rg6GUnDHwvFTg7YdTp6X5YuVP3oS3fbG7rz0DkqVgb2wsUFzao6M2767KfdFRAZDEd00d5eeXp/7QhteLWoR/3f7wm+Xq7mz35tAgAJzMhLoXEm11tr91tpBSc9Kuih+B2vtamttW+zmWklnuBsmkB+F/tB5eMUBVx8v2aiidP+kxbuaXY1Bkg4d69XXH1qb8vezt45PQFw79vHiXqqzOmGFsEdX5v4cYYUwoGSQgwEu8foinCTdneQCWK4eW3VA1Q2pRwA/vc6dqVbJCk33L9uXZGvx6OwfOyPAjeIYUAycFIHeJSn+0nRDbFsq/yEpt3kZANKaOm22q0usZyq+0FB10P356Rgv12aSAIoOORjgQxfdszIvj5vNx3ypTKXyg4kuonmZcwNuc1IESvaMT/oSMcZ8VtEE5Ocpfn+pMabKGFPV0lIa/TdQPJLN0y3kgInjPYPa25xdzxs3ZfsR9n/PV7saRzLWSp+4cZGmTputP716Xt6P52dPrK7T1GmzxzTLtgzxAYKGHAwl4Ye/Hz8tvJBfqX/qcg4z0cibXKT6mH/fFXPycrx4Q+GIpk6branTZuvKV2ryfjw/u+ielTrrl2P/5rn2wgT8xEkRqEHSu+NunyGpMXEnY8yHJT0s6SJrbdLlbqy1D1prz7HWnnP66adnEy9KUDhiNXXabH0rD6szRSITv2FHSvBLdSjNv9mJZH+35zc2jNv2p1fP00X3rHR1+lFjR3Q+ds/g+CXog9Rwb3iljCMdo/PTnT5fSVSAkkEOhrxqaOvV1Gmz9fLm8Z/xuQrH5RKzk/SlcSNf8Ztwjv+mVPdP/Ft19A5p6rTZrkwhHzYQt1jHU2vHTiHb19Ktf30w9bT/UlPd0KGh8Ojf3Fqb87kF/MRJEWiDpLOMMWcaYyZJuljSrPgdjDHvkfSSpEusteOXAAAm8N7Y1Y3leVid6dwbFk34+7+9bZnrxyykZMOG71u6Twt2NI3ZFonYjEaRfOPh9B/04YhVz2BY1Q0d+kkBRgkFReJpGi7o7Draqe8+XuVBRAA8RA6GvNl9tEufunmJJOmlTYddfexQODKS36Vy/u3FnYMl894r5oxb+TTdBcl4z29s0AtJLrolOtweXc3r2td3qLXb/UbTiRL7F5aqVGdq+vzd2tfSU9BYgHxKWwSy1oYkXS5pvqSdkmZaa7cbYy4zxlwW2+1qSW+VdK8xZosxhm8q8IVSWTUqlcREY9iinWOLQH98xRxd/sxmSc7mm6/dn77Hz6dvWZL+gTLEdKfx+oei5zgoCRiAUeRgyKfqhva8PfZgOHl+EgT9odGRzDsaO/XHV8zR4l1NE9xjrNlbxw32G+eLd63IKja/8mv+N5xnP7U29xXQAD9xMhJI1to51tr3W2vfa639TWzb/dba+2M/f89a+2Zr7Z/H/jsnn0EDiNp1NPkqBsk+S2dvPcJQ1iL0tftW6+CxzK4++TSXApAFcjAUoyA30Y3/DN54KLpw35yaox5F446JLiC6ca6HfJqfvv/KzPvs+7WgBcRzVAQCUBq+HqD53NlYXev98rHHYo2g41cC29fSHeiEGgDgvvhPFb635sfw3/iFjQ2aWVU/4b750jc0tsdiqiKFl1lGS9eALy5UpvzbZLBsG68lFAOKQPCV/qHxzYDhnvV1xz1bZnz9gdEpZh29Q0n3Sfzc7B4I5TGi8b7x8LqCHi+Z1u5oItTRG78qmIcBAQBKXlvvYEa9a+BMfMo1b5s3o4E2HmxTZ/9o3vXcBmfFqFQtB/Llqle3FfR4qfQlWZgEKDUUgeArn7p5sdchlIT41aHiP/iz5UYi8C8PrBkpBB3vTd7EMPGD989+Nd/RY3f05f5vzIdsi5rXvLZ9ZJW0Ye19zhs/Dp/9oXBEXS6cfwBA6Ym/KLS9sVO3L3Cvr7hH15v8Ia6W1h530SvbaUJuXBD78K/fGPl54c7mpPsk5lLffMTZhbFM8pOJPO/ySKls85+PXPPGmNuhDHOp4bPcMxDi4jZ8iyIQfCXZCget3QMaCnCDwWw0dw3IWqvW7oExH/zZ+ucH1rgQlVRzuENS6iHH33l8Q1aP++W7V2YZUX599talWd3vlc1jV2lZsbdVN8zZlfHj/OeTVfqQC+cfAFD65m0fP1KlqbM/yZ6YSEt3v6y1mrmhXtPn78758ZxeEHMqVYHuEzeNvRAbP4J7oinpq2qPuRKX27LJf5o7B8Y1Nf/Rc1uUySC54WLfn/5qftGvQozSRREIvjYYiuic6xfq5y9u9TqUorJ0d4vuWVyrc65fOO532VyVcGtlquEPxqBcITzSkV3y3Nk/9qrf/CSJeTr9Q2Et3d2S1fEBAHh1y2F97IZFY4oBSO/825fr/mX79bOE3HW455/XApKCZSXxnEnRhVUyNTyq6nB7X84xAflAEQi+FopEq/Fzi3xVBS8s2Jl8OdK7F9cWOBLkKtNiUkNbn7567+o8RQMACIKquujKVruOdnocSfGZu2184WBrQ4ej+3rVu9FrQ+HS6El1pKN/3JQywG8oAqEo2HEtg5HOwWO9Od0/VfNmN/h5pauXNzc43reutUchH05VfK26UTuPkLQDAJxL1bOGxQkyd6C1J+v71h3Lb26RTY2pUHUpp//ucMTm9DfOp0/fssTrEIC0KALB1+qPM4wyW7k2S/7o9QtcimTUfp9+YMfbfKjd0X4Nbb0679al+u9nNxd8BY1sHWjtyboxJQCgtEz0vT4Ssao7lv1ndtA/arr6s2/mvL+lR7+Zs9PFaKKKYWpSyGHznTsX7tFnb12qRSlGvfvNYCii+uO5XZwF3EQRCL61dv8x/d0dyyVJ/UPOv2SHwhHtberKV1iB4fSDOBNPrzukWdWN6hoonhWr6o/3Jl2Z41isifmcmqP6xUs1hQ4rI3WtPdp4sE2fvXWpnlp70OtwfKGtZ1BHs+zZBAClbCgc0c9e3KoVe1slSce6Bxzft713UEc6/F9s8Ls1+9xvtvzJWOPnYvrs23mkM+nFq/V10T5V//FElTYfait0WBlp7R7QtBe36tO3LFGPCyu9lYJDx3r5W3iMIhA8laoqXtvcrYsfXDtmm9MlMqe/sVuf/+1y7W/pzjk+uG/74Q596S5/ruaVzKdvWaJ/TbI6Wm3z6PNr2R5/N2A+79alI8OmnY50KmXHugf0F9ct0MdvXOR1KBPq7B9SYxFcuQVQnPY0j71gNvxV+4Y5O/XCxtGp0Xdl0Evwr29crL++cXH6HeGJoXBE1Q57E3ltya5mXXjnCj2/cew0/cFQZMxUsFxGrBXCOdcv1NJYntjHkvE6eKxHfzN9ib7+0Nr0O3uosb1Pnf3Fc9E6UxSB4KlU82abu8Zfpfjmw+scPeamg9ErAi1dzq9coXD8PiUs/oJTbSxB3t44tr/O9sYO/eT56kKGlbPhYf87jnT6so9RIX00yap5XtnX0p3yatgFv10+bsleAHDDvG1H9cCy/Ul/t6Fu/Gpgs6obHT3u8Jdcejn6041zdnkdgiPWWr265bAkjetx+KtZ29TUWVw5/nAOtutIsGcqhCNWn5m+VJLzRun5Yq3V1ob2lL//xE2L9fnblxUuoAKjCARfStY4eIvDZcr93HQYUnORFOestTr/9uUjt+OHwx9uK97RGbuOdum2BXu8DgMxf3vbMn3ipsVq7x2/dHBjEQ3ZB1Bc9iSbNh+r2yTLo3azQlhJWF/n/jSzfHhhY4Ne2RItPG462KZwXIuCfEyVK5RvPrKuKHoz5Us4D60msjWrulH/cM8qXfPadkVSxFVsxcZMUASC7zS29zku+CTqHwpre2NxDHMNquoMz238tKtCSHX18rxbl478vHncv8E/H2pOTHTlI2j8sLpIR99QUU2RBFD8kl0u29/ao2PdA9qRZHXJBgcXP5o6RwvXQW8M7VeJI5vTaY1dACvUsvXDz5u9cblfdUOH7l68V5LUMxBSXcLqt8X2XEt20Seo2nq8+1sMf794bFWdHl11wLM4vEIRCL7ziZsW6+Z5yYerHk/zZvF/L2xVz2B0KPKa/cV7pQCjzi/wUMz9LdGiQGJSMbzSx5Jdzbpv6b6CxoT8+eytS8cNNfdC4pXB+MaqFLYBFMpHr1+Y9Gr9q1vSTwf72A2jfdZ2HQ32tBe/yrRg8okC93dqS1Eg2R17Pl321MZChgOXJV5o/YvrFowpHhdSfFlzX0If2fi8q1Qb3VMEQlFJ10k+foWAOxbuzXc4KEGr9x2bsGdOfdv4Zuat3YMl3Tyu1F145wqvQxgnvrEqo4QAFJuv3bfa6xDggsFYPlSoRgup+uANF6/WHxjfr2rt/mNJVxDzkwINpPK9ZKcpvnjsF/F5V6k2uqcIhJLCmyzc8NuFe0aWH02U6il2ySPr8xeQC259Y/fIzz7PlTyR7yVmrbVasrvZ94kqgGAgX4JfHeno04q9rWO2DY8gSfa8nVnVoNe3HilEaFlr7R4d4UQaMN6hY8lXi3ZLW89g3vO8YkMRCJ7p6M195MSRjj6tqm1lugRcteFAmy5+cPzSlRMt151pr6NCO0KT4Ql99d78XrV+fmODvvPYBs2sqs/rcQDAiQOtuX/p2na4Qyv3tuoony+uK1QPHj+6ae6ucdO01+4/rv4JlldPNkob/pOqAPY305OvFu2Wf3lgTd7zvGJT4XUACK5vPZb7yIn4IXp1N32JlcFctq+lWwdavG+cW2ipRgF94qbFuu4rf1bgaFAoa/Yd01+/9615eezhAuLh9tRflg639+ldp03Jy/EBIN6Lmxpyfowv3z06ZaLupi/l/HgYtfNIpxraenXoePCKG8n6T3X0Dema17aT5xe5VIuvSFJtc5fe9/Y35eW4e9MsMrNkV4sGQmFNrijPy/H9iJFA8Ew2KxQFeVlFL/ztbcv0vServA4DKIivP7RWvYMT9x3L1ZyaIxpK0XPqkyl6IQCAH6R670J+fOrmJfrGQ+u8DsM3dk/QbJwpVsVhovN0/u3L8378ZXtaRm/EjbY72tmvm+YmX5SoVFEEgieaOvuzesNONkVn2NyaI4G8YgJkavW+Y+qikXVSSRbFcVVtc7dmLKnN+H6ra1vT7wQADmzJcvryHQv3pPzd3Bp/92RBbvwwO61U6jxvbD/qdQie8focfvvR9epOscjQRH2JaptLb7VDikDwxGdvXer6Y37/95tcf0wgkQ/yIFf873NbvA7Bl/JxfgdDEb2y+fDI7eHlUDNpEv2Nh7kaDMAdX5mxKqv7TdR8lxwM+WatP4pRubprca2qUrQdKHVeLI5RnzBAIBy72pf4VJooskKMUio0ikDwRO9g6uZu6SQ2i0PpW7G3Jf1OBTIryVz1YrRwZ7PXIXgi3TTUsjxkmPcs3qu6PK98AQD5dpD3sUDa2+SPURBNnf05fX/wk6DmBAt2NBX8mPkYeFAKKAKh4A605tZoON89O+A/flp+PVXTaBSHf7gnuyvguWjuGki6fU5NZkPCWV4eQK6YWopMff63y33RkLmUVjn96fPVXodQcM1d/frxzML/u0NJ5vkPhMJ6PmG11qDlWBSBUHBuVWSzaSyN4tXanfyLNDCR17c2jqzM5cREK1eksvlQmzZkVBw06uwf0g+fzmz6RMDyEwB54NbUUnoABYvfc+6gTq/ys8FQRE+uqRuZfjUwlJ/G8pnmecZIv12wV40lVFTMBkUgFJ3hL0JeXNGHdy773UavQ0grVbM5v2ruLO0PQGutLn96s/7pvtVasrtZtWmWCJWkFzcdTrtPoq/eu1r/fP8ard7n/Ap7OJx5RYcaEAC/oAdQsDywfL/XIUxoyW7/tA1wKpLvlSg89uDyfbr61e2aWVWvp9cdUt9Q+ql8a/cfy/g4lz+9WZ+4abEOHnM+04QLyxSBABSJpi7/Fyz2+GTevFPn3rDI6xAKorGjX995bIPOv31Z2n2vemWb6rKcsup0Kd9n1h9SV3/mBcOgDVUGAMCpfgdFBj+5b9k+r0PIq/be6Cq0v3ipRle8XKMb5uxMe5+JVoFOx0mOJ0nPrj+UdHvQMiyKQCg6QXuRIqr+uPOhnl75x3tXj/y88SBDk72Wbc3k2Q316XfKQLJe01e9ui3pvhMNuee9DwCA5O5dUjvy86tbMh/VW2jT5+/2OoS8Ssx9jnUPOrrfugxGA8VfHBtyOML6hjm7kl7sW7q7Rcd7nMVYCigCAUAefO2+NV6HEHhPrTuY1f3uX7ZPnf1DLkczVkdf8sefaJorA4EAAEiuMzbC1lqrHz27xdtgAq57IKSHVhwYs63mcIej+/5rBqOBss2LkjWLlqQfPbs5uwcsQhSBUHRqGpy9iQAIrubOfl396vas7x/KomdPJrJZif7pLItaAOCWjt78FsiBbA2PCuGCifecTP3yUqocrHWC0Uor95bWyooUgVBQbkyRufb1HSXfTA3Fq3sgpLsW7fU6DMdqm4urj5FTqa7yOPXAsn1Z9eCZPn+XXtjYkHa/iWpAqZZw/vVrO2hmCCBrLzp4b0rnI9e+4UIkQH5sb+zQS5v9PxVs2ECouPoYOZVN38N4C3Y0OdovMUubPn+Xo++aE+VgT69L3jPom4+4s7KiX1AEQkG5NUVmwU5nbw5AoU2ft0u3L9jjdRiOXXDHCq9DyItsRtrEe2D5fu1rybxB9Iwl+/TT56v1+KoD6XdOYaIlnCNc4gSQpZ88X+11CEDezNl2VF+6a6V+WkTP80dWZp8r+FmOKZj+88mqrO43Y8k+fe2+NVq2J7vV4qy1uuLlmqzuW2wcFYGMMRcYY3YbY2qNMdOS/P4Dxpg1xpgBY8xP3Q8TGGtpES4FiWB4Yk1xTdnJdcSMX5mcUxApFIlkfd9fv7ZjTDSJyrKsUrnx70JxIQeD3zS2+3+hBgRPS1fxjZTtHyzNkUC5XohzKtWI7W8/un7C+2Wbg5WStEUgY0y5pBmSLpR0tqSvG2POTtjtuKT/lnSr6xECSTyTYnk/AKXp/mX7tLepdKauZZt/lJG3BAo5GPzoEzct9joEAAXSPRDSb2bvKKmpa6lysF1HSyfPTMfJSKBzJdVaa/dbawclPSvpovgdrLXN1toNkugWh3FmVTdqxV5G7gDIzlA4opvm7tJX713t+D5uXORxMvNqbs2RrB57Q11bVvczXL0KGnIwZM1aqzsW7tFhRu4AvlRdBIvd3L14rx5acUDPpOiVk0whMhVrre5ZUpvVfbPNwUqJkyLQuyTVx91uiG0DUrpv6T5tiy0F+N/PbNYlj0w8LA8A0ukfKuxVKCdFoO//flPK392+YE9WzaUnQgkocMjBkJHewZB+PWu7egdDqm3u1h0L9+r7T230OiwASWTbu6aQhkLRPMZv7QNaugZ0x8LUC7G8Vt1YwGiKj5MiULKcM6tngTHmUmNMlTGmqqXF/096ZO/mebv05btXau3+Y16HAqCIWWv1m9nRpUZDEet4hUE3iiVXvlKjUDj7vkB3LdqrNpeXU/71a9tZHTFYyMGQkUdXHtDjq+t09tXzR5Y7LnQBHUBpaO7q16OxhS6un71THX3Ocho3Ri0/lmaBjXQfhP/1zOacY0j0+3XF1fdzIk6KQA2S3h13+wxJWZXWrLUPWmvPsdaec/rpp2fzEPA5a62mz981cvviB9eO/PzDCa6YA0AyjR39enx13chtxysMulAF2nSoXav35V7IdnMG16tbGnXJo+tcH2EE3yIHg2NtPYO69Y3R1Sm//lA0B9vT1K0fPk0OBiAz14xZ5EKa4XD6lRtpT+Kx/eCXL2/TixsbvA7DFU6KQBsknWWMOdMYM0nSxZJm5TcsFKvugZBmLNmX9Hezs+ydASC/VtW2eh2C69xaRSvXUktje5+ezmAevROrao/paGe/q48J3yIHg2PT39id8nezt5KDAX7U2u3jVc18fL3JSZa3eFeT68f9yfPVrj+mF9IWgay1IUmXS5ovaaekmdba7caYy4wxl0mSMeYPjDENkn4s6UpjTIMx5pR8Bl6MXt7coOer6tPvCAAF9G8Pr/M6hJSSfcinazQfjlhd9co2V46f64ibX75c40ocicJMCQsEcjB3WGt149ydI70KSxUjBIHic/PcXel38kpCEvbg8v1q7pr4IlT98V69tPlwHoOKcVAF+u7jVfmPo0g5GQkka+0ca+37rbXvtdb+Jrbtfmvt/bGfj1prz7DWnmKtPS32c2c+Ay9G//tctf7vha16YFnykTKlgJVrgNLxuzV1emqtt/Ofy5K8pyQ2mp9Tc0R3xjUHrDncoXnbj7py/Fy/U+Vr5Y9QmC97QUEOlrvBcEQPLNuvL9+9Uiv3lt7Ix1HkYEApsNZq2otbtaW+3dM4kuVg1yZM05o+f5cW7hgdcfOTmaUxUqbUOSoCwV03+rTiO33+Li3PsUs96QdQOq56dbuufGVb2uZ8qTy97pD+5f41enRldveXnPXT+cHvN+m3C/ek3zEL1qdjof22SgdQLL75iP9GPvYMhPTD329SS1du00K4DgeUhs6+kJ7dUK+vzFildVkssmOt1ZWv1Ohf7l+T0yI9Tt5SZizZp+89WfgRN25N+w8qikAYMWPJPn3r0fV6dUv2Q/hIQIDSk21zvitertH6uuO69vXCNPf71avRKWBuvg1Fsl8cLK++8/h6DYZ8GhyAjLy0+bBm1xzRX/1moQ609mT9OKRgQPFJekkn7sX8r3GL7DjVPRDSU2sPaX3d8TGL9OTTSMPkAr0Refmd8/YJ+q8VC4pAGOdHz26RJN27tHZkpa/XtzY6WmqP6egA3JTuQ/7hFftHfn5izUFd9ruNrh7fr29p9cf7tOMIM34AJ/yem8S/zV0XK5p/74kqLdoZnWJx7Ws79LiDEZlciAOKzwtJVpvK9bXs1mDhsjRx/OD3oznXT56v1oPLS7flSby7FjtbJc3PKrwOAP51y7xolfPpdYfU1jskSRoMhfXAJeekvI/P8ywARSbVcN+n1h7UNz/+R7p+9s4x2+dtP6offPa9rh3/P5+sUvXVX9CpJ1a69phuoTk0UBriv/ANN3deuLNJC3c26S0nTdLxnkFJUn8ooss+k/r9jekRACS59oUsWa/X17ce0Q/O69TZf3iK5tSM7b94w5xd+tiZb3Hn4JJ+9kK1bvmnjySPzbWjBBMjgTzy4+e2eB3ChO5dOlrhHC4ASdL87amX2hsIhfUPd6/Ma1wAvPF/OS6J+dMs75/qatiVE6z+5fYXode2No65fax7QH9721Ltb+l29TiZoggEOJM4EujpdYe8CSSF+PesJbtbVFV3fOT2cAFIkm6aoKfk9sYO/c7jRv4A3JGYxczMcHXpSMKb3swN2a1OnSqb+vWs7anv42IKNrNq/CipJbua9bX7Vrs22imoKAK5pKahQ39/90r1DoYc7V+QpfNyMDwKKJlUS5AePNar/TnMZQfgnSfX1I25nfgB/3yS4cqZSDbc2YlspnF84yF3579f+co27YybejVv+1Hta+nR525b5upxMkURCIh6bNUB/fyFrSl/n9jg/YqXa/IdUkYSvzT9aoIvWKncOr/4e1QAQbW9cXQl0YFQWF+7b/WY3/9sgve3ZBKzg5+9mNn90z9+6vxj7f7jKX+Xja/MWDWmB+LlT2/SxoNtuuCO5a4eJ2goArlgxd4W/f09K1VzuENnXz1/zFWbYvGVGasc73v+7cu0+VCbPnnTYnX0jY4SSjdvFIB/Xf3q2C8dj6+u8yYQF3QNOCvGZ+K2uCaAyZZM9ULilb5szFhSqx8+vcmFaABvTJ+/S9e8tkPPVdXr3x9bn3QfP/cEqj/eq1+8NLYotb0xdb+vX75co4dX7Nf3nhi7Go9f3pcAZO7muIvvda292tOU20hjN/IDKfl0sELbUt+uhrbekdvD73XHivD7dqJLHlnn2QhOikAuuCphWsKyPc3j9nHSVNlLW+rbHe+7r6VHX713tQ639+kj17yhIx196ugb0vm3U5EF4K6JrjYNrwZWCAt3Nmv5nhbVtfaM+8LmlX97eF3OFx2mz9+t2VuPuBQRUHgzlow2Il26u2Xc7wdCYX3shkWFDCkjz2U4TeP36w7p+tk7tXBnk/4+NgV/2Z4WLdo1PvcEUHzKXfh27l4RKPn2DXVtWrAjdYsQt33utmXq7B/SM+sP5eVCXzYufnBNzo+xYm/ruDpCodAY2gWJVdJkr7vXqhvHbywRf33jYl33lT/zOgwAJaZ7IKRzf5P6y9sTawp79WT6/N367J+cXtBjprNu/zFd+KF3eh0G4FvNnQPq9smXhmRyGUVdc7hD59++TBUMxQaKWvwr2I1RfW7UgFbva51wKv+1r2c+bTUX2w93+uYinOT+tLdCYySQCxJfqn4edpwoFI7oI9e8kfPjvJBhwzIAxeeLd64o6PF2+WwJ9JrDHXrdZ6NmQvQFAopWTUNHzksN1zZ3+2LKBoDstfWOjupNVQS6eV7qxvCJ3PguOj1Nn7H64325HyQDX3e532PQUQRyQ8Jr1enrrtBfqJLpHgiN6euTLb6GAKVvRwZFmcR+FZJGpi445ccvNn5rfk9zaCA7N87d6XUI4xryAwimrQ2jjaHLU4zsu2/pvqTbE/UPhfXxG8ePor4lgyKSRJ+xUkcRyAWJL5GfPl/taOngTL5Q5UuZS0OI49+8AJSuqdNm6wNXzU25SuCwhTvHzxWvOZzZ+wT5R3r/89wWVx6nfyjsyuMAXvvodQsc7ffAsv15jiS9VF/2MrXTB/kkAHdMlPtMnTZb339q44T3j2+iHO9eh0WkkTgy2juYfvj74l1YgyKQC5Jdrf7cbcsyarbs1EAorKnTZuvpdYdceTyqvACGOf0w6x+KuD4N6Y3tRzV12my1xTU65t3JmYgL5yJ+KDpQzI71DGrqtNkjrws305x1+49p6rTZKb9kZcqtC3EAit+rWw5LSv/dbO62o64f+2cvVOtzty4ds42viOnNrvFXi4BMUARyQarP8Fc2H3b9WN390eaGt74x8TxNp9JdzQcQHJl8mLk9DenRVQckSX9x3QI1tkfnmVOkdmbtgWM5P4ah5IYSk49+Wc/HmqSu2Zf7a06SynmPAxBzb2ylQy++mc2satD+1h597IaFI9v8OCXfjwZDEa9DyApFIBek+qLi1vJ88Spi6wYe7xnU3Yv25vx4lIAAZOMDV81T36B7U4gq49ZEXbs/+gWL/MOZmRkuMf23ty3Vdx/fMGYbAxJQaoZzMDe/yAy/T/3fC1tdmYLl1nQwAKXDyQX6C+5YnpdjN3UOjPzMu5MzfRlMp+8eCGnqtNma6YMFlSgCJRGJWE2dNltTp83WrWk6o08k34NsbluwRzfOcdbYcPGuJk2dNlvNnf0j27r6h/ThX+e+MhiA0vK1+1Y72q+1eyD9Tg7FF4GGwtGrKowEcuaVLY2Oe/r89Y2LtK+lR4t3NY/ZzhU/+MXGg20jOVh1DtPq85GDVZaPvk4uvHOFNh50tkTwz16o1l/9ZuGYbQt2NOnx1XVuhgegyA2FI/rUzUvS7rfraFfeYyEHc+YrM1Y52q+la0B/9qv5kqT7l2XWnykfKAIlET+E+J4l6ZfuTJU8/27tQb2+tVFTp812LbbE5dwfWO6sseFTa6M9hM69YZFqm6NNqxvb+ye6C4CA2niwzdF+n75liY5lWAhK9n743IZDY4oSg2HGKGbK6SpDRzpG3/fd/GwC3PJadePIz3Ny6LfwwavnaU7NEX3ypsVuhKWNB9v05JqDY7a9tMnZtP+ZVQ1q6RoY85r73dqDE9wDQNDsa+lWz0DI8f5/cW3mF/IveWTduG3ffnR90n2pATlzoLXH0Urbe5pGC3f7W3o8z8EoAuXovqX7JhwSfPnTmye8fyZPgFz698QPOV4Tm2rBMGQAuXJjyfTfJzS6v+qVbdp2uIMEJAOJX04zRX84+EX86z7dtPq/v3vlhL//QZpm9//28FrHcb2xfXwz1uFRi9moIAcDECcUsRmNYGzrTV94SLRib+u4bcv2tIy5PfzdlBzMuSMdfWn38dt7PkWgJBKTjh89Gy3kWGtH/ht29+Lc+/Ikmjpttq54uWbc9lSNWC/73cYJE/iZG+q1YMfocs1XvbJNGw+20QMCwDiZXln65/vX6NCxzFbKGZ7qMXzFa3LF+I+iL9+90rXmq0GQa2PCPPTQBbIS36T8oRUHtDCWvyTLwWoOd+R0rFW1Y99jdh7p1NRps7V63/gvSskKUjOrGjSn5kjKHMxaq28lXGUf/oJFDgYg0V9ctyCj/bMZTTJ12uwxDaBT7RMpzn7HnnCyuEZlklzXS/6Kxge6B0L6wFXzxmx7dUt0aPLXH1qrM38xR2f+Ys7I7+L7WGQrWfKQbAn4VCtdzNt+VF+9N3kPj5c2NehnL24dt/13a+r0uduWZRgpgFKXzZWl6ob2LI818bLkL8RW4kF6zV0D2t6Y/RfifCxkAGTq9a2NIysFDnsltmzycP71jYfGT2dwy3BT+vlJlmBOVSj9we836akUU7sueWS9lidcZZekR1ce0MKdzUnuAQC5cfJxHt8AOpV0ORpG/Z2DRt2VZf4qu1R4HUA+RSJWEWtHVtRyItWcvgvvXDFm2tfUabO15/oLc45R0khRae9vLtRZv5w7sj0SsSqLXSrqGwzrg1fPS3p/SdpS365QOKIyYxSKWN21aO+E/Yx2N3W7EjsAJI5SjDgcVvKpm5fop194vzbUJe9BVIjGh6Xk0ic3atW0z43bHgpH9L64z5ZkKALBbcM5SVkGQ17m1owvvvQPhcdc7V6z/5guuGO5Zl3+KVfinDptts7/4Nv13U+eqWte2yFp/Gov87cf1SMrDyS7uyTpiTUH9c2P/5HCEauIlT5761Idbk89PYB+QADyZVXt+JGMyUydNlsfO/MtKX9PDpaZutYeTX3bSeO2HzzWo89MX1r4gNIo6SLQ1+5frc2H2rXvhi867n9TnmICZLK+P++/cuKkOlNnJSTpX7xrhV7/r2iS42QVnr+5ZYk+dMapmr+9Ke2+bixtCgCSNBAa+4VpMIM+Gbcv2ON2OIF1uL1Pq2tb9Yn3vW3M9nQFICn/q1kieN73y7n6/Nnv0APf/KjjQlCy/ZKNmNl1tMvVHGzhzuYxx5lZ1aBzz3yrvvLnfyhJemXzxA2ga5u7desbuzVjibMVXw640EsNAKRowT1+wMPuJufFm3UHnK1wiPTOu3Wp6m760phtO4906sI7V3gU0cRKtgg0FI5o86F2SdJ7r5ijXdddoBMqy9Pez08jtXYd7XKUvA9r7OhXYwcrfgEorJ+/WKMP/MEpev873iQrq7Ovnu/4vvSicdeCnU1jikBOl45nJBDcNPy8W7CjSf/8wBo9e+nHHU2f91PjzJ8+X62fPl/teH+nBSAAcNP7fjlXdTd9Sb2DIW0+1K5n1td7HVJg9Q2GNWXSaL3Bz70tfVTycNd5CcOuPnDVPHX0Do38BwBwzxs7juqDV8/LqAAE9z22qm7MEtuJPe5SoQYEN8U/7zYebNNnblkykn/1DqZeAplVSwEgczOr6nX21fP1bw/nr2ca0vvg1fPUNxi9CLJm3zFd+/oOjyNKrSRHAvUPhZPOxf5I3Ko38/7n03rnqVN06pTKMft0pugJBABIbfdR+oz5xWvVjfryh9+p7oHUX7YTMRIIbunqH59HNXb0j8nBtv76Cyo3RidNHk1DrbUTFogAAMnN3MDoH79o6RrQe9564piVuf2oJItAH74m/RLHF9wRnZ93/zf/Uh/9o7fImOgSu+ffnr67NwBgrIU7/f1hFyRv7GjSzfN26/5lzqenMC0PbhgIhfWhX6fPwT4c22fjledLkqyklzcd1pwkjaEBABOrOph8gQ0U3t9MX6L//tz7xq106TclWQQaDDlvSnrZU5tGfp6oQzoAAMUikwKQFB2FAeSqf8h5/iVJH71+4cjPJ08uyZQUABAwdy1OvUK3X5RsT6Bs0CEdABBE7zxtitchoAREchhSlsn0RQAASsG5U70ZhEIRCACAAJv61hMZhQFXDIUzGwkEAECQfeJ9b/XkuBSBAAAIsBANgeCSgQym4wMAEHRG3qyKSREIAIAA6x8Kex0CSgQjgQAAcM54UwOiCAQAQJC1dg96HQJKxFCYUWUAADi1vbHDk+M6KgIZYy4wxuw2xtQaY6Yl+b0xxtwV+/1WY8xfuh8qAABAsBRTDtY9MOTVoQEAKDp1rb2eHDdtJ0hjTLmkGZI+L6lB0gZjzCxr7Y643S6UdFbsv49Jui/2/4J7eXODF4cFJElvmlyhRT/9jCTp3N8s8jgaAEAxK7Yc7Gv3rfHisIAk6Zp/+FNd8Gd/oO6BkP72tmVehwMAaQ2EvJmS72Qk0LmSaq21+621g5KelXRRwj4XSXrSRq2VdJox5p0ux+pIdb03Q6rgP2UFmGN54z9+SCt//tmR29/79B/r7W86QW9/0wnaee0FKe9XffUX9N+fe1/+AwQAFLOiysGAQtp01ef1iws/MHL7vD85Xe845QS99/STtfmqzye9z8mTK1R99Rd0xpunFCpMAEjpyx/+Q0+Oa6ydeP62MeafJF1grf1e7PYlkj5mrb08bp/XJd1krV0Zu71I0s+ttVUJj3WppEsl6T3vec9HDx486Oa/RZLU3Nmv+rZe9Q6GdUJluQaGIppUEa11lRlpyqRy9Q1GK26hiJW10YZMEWt14qQKVZYbhcJWoUhEklFFrJJgjBT/p7KS+gbDestJk2RlFYlInf3RYdAVZUbGSBVl0eNGrFVleZkG4xomTq4Yrb/1D4VH9h0MRzSlslxD4Ygqyso0EArH4pMisRVcysuMjDGSrAZDVoPhiCrLjSZXlCkUtuodCqss1mXqzSdWqqNvSOVlRidNqtBbTpqk7oGQBmMreAw3o6ooK9OkijJVlhv1DYXVMxA9bvTvZ/TmEydJkirLy3SgtUcnVJarzERvD68sE7FWp5xQqcpyE/fvCaujL6TKcjPS/XwoEtHpJ08e+fe39Q6O6Yx+0uRyhSJ2pFlpZXk0rv6hSMI5sCNxxf9dK8vL1N43pKlvPVHtvUNK9gzPtj6U+FhvOSl6/PbeQQ2Frd528qTYuYnqGwyPa7paVmZ06pRKWWvV1ht9zlhrR+5nYscZfpRjPQOaXFGeNJ7JFWWyij43K8vH/6tMQrex7v7QmAZkJ04qH3muDDva2a/+obCsoslSZXmZypN0LYtYq+6BkE6dUjmyra13UH942pSR/Y909GsgFNabTqhQKGKjz7PyMnX0DckY6ZQTovcNWzsS26lTKtXWO6hwJPo3iS/mGRmddmLlmDhSvYUZE31t9Q6Ovh5OOzH62MOPNeyUKRUqM0Zd/aHYa186obJcJ8T+7sPvEZ19IdmEZ0HiczBRsvgybQLX2T+kSETjjh2vvMzo5MkV6uwLjWxL/Fulim0wHP07VZSV6eTJFaooNzra2a+hUEQDoYgmV5TphMpy9Q+FZYwZ8/4lSRWx983oY0XfwyZXlKmszGgoHNFgKKKT4pYgj39NVJaPPlZbz6CMMaooNyozRtba2HuNUSgSGTlnfUMhnTy5UkPh6Pt74mtGij6njncP6m1vmiyj0V4lleVmJJbugZAi1urUKZUKhe2YWIZ19g8pHLEjnwXD7/1TJpXL2uhrf/h1Fv86Hj4nbzqhQqGwHTnnxkSfe+GIHfOaHQiNflYpdoz4lZZOmlw+cs6GX/fD945/VrT3DsU+P4x6h8I6/eTJI/+ugVB45PNPin6uTK4s05+8401jzo+bjDEbrbXn5OXBA6DYcrB9Ld063jOovlgOFgpHVBF7/lWWG5XH3hOs1UieNhiKaMqkcpWXmZEcbLjBdLLXpDS6ot3Jkyuiz/dyo47Y5/3w66qiLJqfTKks12A4ouF812psDtYzENaUynJFbPS4leVlI6/XvsGwJsfe+4YN/z4cie4fCludOKlc4YhV2FoNhCIqN9E88LQpk3S8d1BTKss1pbJ85DMocTWYKZPKZIxRuTHq7B/SUNgqYq0iEaspk8pHXp9lxqj+eK9OqIz+vUZf/dGf33ziJFWUjcbf0TekgVB4zN+xzBidckLlSF7b0Tc05rPlzSdOUkffcG4Sfe/pGwrL2ujn4LDhz4v4z7OTJ1cobK1CYavTTqwc834TL/49a/h9M9O8rMwYnRr7jDvWPSBjzEhONqyjd2hMzFL0e8Dw51my+GwsJmk0NxnOaRM/u0+aXKHewdDI55Q09nMo/thWUu/A2OO96YTx77t1x3o0vGDjm0+sTPka6BsKR7+7VEYfIxSJqHcwrHedNlrc2t/aI2ut3nHKCWrvHdJpJ1YqYq1auwfHPHbvYFgDobAmVZSpoqxMvYMhDYWjn1ERqzE5YLq8YuTfm/Dcqiwv0+SKMnUPhMY8/+Nz+fbe0emkw3nZ8GP1xz6/4s9BmTFjclCnMs3L4vPG+O+D8a+bKZXlstKY7y4nO/xc7eoPKRx7rU+uKFM4YtXcNSBrrfqGwiO5eO9gWJMqRr9jDYvPwXoGQ3rrSZNH3gd7BsKqKDeaVFE28hoefn81MrHvlKM5rqSR9+KhsNWbTqgYk0NFYu9xJ0+uUCgSSfn8HBiKqD8U1mlTKmU1+lo4sbJClRXRHKijbyiaL1aWKxy2qigf/c497HjPYPQ9d/hxQxGVl5nY+5/U0jWQNAYb+14/Kfb3tIp+559UUabBWF4rRV+XobBVednY7xvtfUOyNvo4kyvLx+Rrqf7NktTcOaCK8ui/Lxyx+oNTTxj5XVf/kMKR6GMOf1aVl5Xpw+86VWV5GrkwUQ7m5NmZLKrEl4+TfWStfVDSg5J0zjnn5KV74NtPOUFvP+WE9Dsia+9+y4m+fjxJenMsEXjzSRN/QXfLaSkKAVMmlWvKpOQFnGQJSzJu/hvyfbzEc5ntY+XjOVGIxy4lf3gaV0kljfkABzxQVDnYe08/We89PR+PXDpy/Qw6820nOT9WlsfI9n6JTqhMnv+47a1xFxbjnTpBweKEynJH8b39TRP/3kleNeLk9Lu4mfN9NO6x3v2W0e1/9Fbnz6FCio/RT7zIG6dm8DovVme8Of0+7zx14lz0/e9I8wItML/FMxEn08EaNPbz4AxJjVnsAwAAAOfIwQAAgKucFIE2SDrLGHOmMWaSpIslzUrYZ5akb8VWqPi4pA5r7RGXYwUAAAgScjAAAOCqtNPBrLUhY8zlkuZLKpf0qLV2uzHmstjv75c0R9IXJdVK6pX0nfyFDAAAUPrIwQAAgNscdayy1s5RNMmI33Z/3M9W0g/dDQ0AACDYyMEAAICbnEwHAwAAAAAAQJGjCAQAAAAAABAAFIEAAAAAAAACgCIQAAAAAABAAFAEAgAAAAAACACKQAAAAAAAAAFgoiuLenBgY1okHczTw79NUmueHhvu4Tz5H+fI/zhHxSGo5+mPrLWnex0ExiIHCzzOUXHgPPkf58j/gnyOUuZgnhWB8skYU2WtPcfrODAxzpP/cY78j3NUHDhPCAqe6/7HOSoOnCf/4xz5H+coOaaDAQAAAAAABABFIAAAAAAAgAAo1SLQg14HAEc4T/7HOfI/zlFx4DwhKHiu+x/nqDhwnvyPc+R/nKMkSrInEAAAAAAAAMYq1ZFAAAAAAAAAiFNyRSBjzAXGmN3GmFpjzDSv4wkSY8yjxphmY8y2uG1vMcYsMMbsjf3/zXG/+0XsPO02xvxd3PaPGmNqYr+7yxhjCv1vKVXGmHcbY5YYY3YaY7YbY34U28558gljzAnGmPXGmOrYObomtp1z5DPGmHJjzGZjzOux25wjBBb5l7fIwfyPHMz/yMGKBzlYbkqqCGSMKZc0Q9KFks6W9HVjzNneRhUoj0u6IGHbNEmLrLVnSVoUu63YeblY0p/G7nNv7PxJ0n2SLpV0Vuy/xMdE9kKSfmKt/aCkj0v6YexccJ78Y0DS56y1H5H055IuMMZ8XJwjP/qRpJ1xtzlHCCTyL194XORgfkcO5n/kYMWDHCwHJVUEknSupFpr7X5r7aCkZyVd5HFMgWGtXS7peMLmiyQ9Efv5CUlfidv+rLV2wFp7QFKtpHONMe+UdIq1do2NNqx6Mu4+yJG19oi1dlPs5y5F3zzfJc6Tb9io7tjNyth/VpwjXzHGnCHpS5IejtvMOUJQkX95jBzM/8jB/I8crDiQg+Wu1IpA75JUH3e7IbYN3nmHtfaIFP3wk/T22PZU5+pdsZ8Tt8Nlxpipkv5C0jpxnnwlNsR1i6RmSQustZwj/7lD0s8kReK2cY4QVORf/sR7kk+Rg/kXOVhRuEPkYDkptSJQsnl8LH/mT6nOFeewAIwxJ0t6UdL/WGs7J9o1yTbOU55Za8PW2j+XdIaiVyv+bILdOUcFZoz5sqRma+1Gp3dJso1zhFLCc7m48J7kIXIwfyMH8zdyMHeUWhGoQdK7426fIanRo1gQ1RQbbqfY/5tj21Odq4bYz4nb4RJjTKWiycfvrbUvxTZznnzIWtsuaamic5Q5R/7xSUn/YIypU3Tay+eMMU+Jc4TgIv/yJ96TfIYcrHiQg/kWOZgLSq0ItEHSWcaYM40xkxRtAjXL45iCbpakb8d+/rakV+O2X2yMmWyMOVPRZlzrY8P3uowxH491aP9W3H2Qo9jf9BFJO621t8f9ivPkE8aY040xp8V+niLpfEm7xDnyDWvtL6y1Z1hrpyr6ObPYWvtNcY4QXORf/sR7ko+Qg/kfOZj/kYO5o8LrANxkrQ0ZYy6XNF9SuaRHrbXbPQ4rMIwxz0g6T9LbjDENkn4l6SZJM40x/yHpkKR/liRr7XZjzExJOxRdLeGH1tpw7KG+r+gqF1MkzY39B3d8UtIlkmpi850l6QpxnvzknZKeiK1cUCZpprX2dWPMGnGO/I7XEQKJ/Mt75GBFgRzM/8jBihevowyYaDNsAAAAAAAAlLJSmw4GAAAAAACAJCgCAQAAAAAABABFIAAAAAAAgACgCAQAAAAAABAAFIEAAAAAAAACgCIQAAAAAABAAFAEAgAAAAAACACKQAAAAAAAAAHw/wHqXt0gW9Ln9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "X = move1_df.drop(\"target\", axis=1)\n",
    "y = move1_df[\"target\"]\n",
    "\n",
    "max_size = move1_df.shape[1] - 1 \n",
    "x_vals = list(range(0, len(X.loc[4].dropna(axis=0))))\n",
    "y_vals = X.loc[4].dropna()\n",
    "\n",
    "f = interpolate.interp1d(x_vals, y_vals)\n",
    "\n",
    "x_new = list(range(0,max_size))\n",
    "y_new = pd.Series(index=x_new, dtype='float64')\n",
    "\n",
    "\n",
    "for i in x_vals:\n",
    "    j = math.ceil(i * max_size / len(x_vals))\n",
    "    y_new.iloc[j] = y_vals.iloc[i]\n",
    "\n",
    "\n",
    "y_new.interpolate(inplace=True)\n",
    "\n",
    "fig , (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n",
    "\n",
    "ax1.plot(x_vals, y_vals)\n",
    "ax2.plot(x_new, y_new);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec69fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5230</th>\n",
       "      <th>5231</th>\n",
       "      <th>5232</th>\n",
       "      <th>5233</th>\n",
       "      <th>5234</th>\n",
       "      <th>5235</th>\n",
       "      <th>5236</th>\n",
       "      <th>5237</th>\n",
       "      <th>5238</th>\n",
       "      <th>5239</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1       2       3       4       5       6       7       8     \\\n",
       "0  0.0171  0.0073  0.0024  0.0024  0.0024  0.0024  0.0757  0.0317  0.0024   \n",
       "1  0.0488  0.0073  0.0024  0.0024  0.0024  0.0024  0.0171  0.0488  0.0024   \n",
       "2  0.0073  0.0073  0.0024  0.0024  0.0024  0.0024  0.0269  0.0391  0.0024   \n",
       "3  0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0659  0.0342  0.0024   \n",
       "4  0.0024  0.0024  0.0024  0.0049  0.0024  0.0024  0.0098  0.0244  0.0049   \n",
       "\n",
       "     9     ...  5230  5231  5232  5233  5234  5235  5236  5237  5238  5239  \n",
       "0  0.0146  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1  0.0049  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2  0.0049  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3  0.0098  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4  0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 5241 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_ex1 = load_data_DB1(subject=1, exercise=1)\n",
    "\n",
    "# Trying to classify 5 movements from exercise 1 in subject 1\n",
    "x = pd.DataFrame()\n",
    "m1 = get_full_repetitions(data=sub1_ex1,movement=1)\n",
    "m2 = get_full_repetitions(data=sub1_ex1,movement=2)\n",
    "m3 = get_full_repetitions(data=sub1_ex1,movement=3)\n",
    "m4 = get_full_repetitions(data=sub1_ex1,movement=4)\n",
    "m5 = get_full_repetitions(data=sub1_ex1,movement=5)\n",
    "x = x.append(m1,ignore_index=True)\n",
    "x = x.append(m2, ignore_index=True)\n",
    "x = x.append(m3, ignore_index=True)\n",
    "x = x.append(m4, ignore_index=True)\n",
    "x = x.append(m5, ignore_index=True)\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d78466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 1, 5, 2, 4, 4, 3, 2, 1, 3], dtype=int64),\n",
       " array([5, 1, 5, 2, 5, 4, 3, 2, 1, 3], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns with Nan values \n",
    "df_no_interolation = x.dropna(axis=1)\n",
    "\n",
    "X = df_no_interolation.drop(\"target\", axis=1)\n",
    "y = df_no_interolation[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "np.array(y_test) , rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b739dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b88a1e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13, 0.44, 0.43, 0.  , 0.  ],\n",
       "       [0.89, 0.06, 0.03, 0.01, 0.01],\n",
       "       [0.08, 0.  , 0.08, 0.04, 0.8 ],\n",
       "       [0.09, 0.07, 0.81, 0.  , 0.03],\n",
       "       [0.8 , 0.08, 0.05, 0.05, 0.02],\n",
       "       [0.08, 0.  , 0.03, 0.12, 0.77],\n",
       "       [0.  , 0.  , 0.  , 0.88, 0.12],\n",
       "       [0.06, 0.01, 0.01, 0.85, 0.07],\n",
       "       [0.07, 0.83, 0.06, 0.04, 0.  ],\n",
       "       [0.02, 0.92, 0.05, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7843f6c",
   "metadata": {},
   "source": [
    "**Trying Logistic regression for classifying first 5 movements of one exercise of one subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80fcbab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_interpolated = interpolate_dataframe(x)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creating a model to classify 2 movements after interpolation\n",
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2)\n",
    "\n",
    "\n",
    "log = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293161bc",
   "metadata": {},
   "source": [
    "**Trying Random Forest Classifier for classifying first 5 movements of one exercise of one subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957d2f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_interpolated = interpolate_dataframe(x)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creating a model to classify 2 movements after interpolation\n",
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26172b",
   "metadata": {},
   "source": [
    "**Trying AdaBoost Classifier for classifying first 5 movements of one exercise of one subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce7a212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_interpolated = interpolate_dataframe(x)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creating a model to classify 2 movements after interpolation\n",
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2)\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "abc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02405ed4",
   "metadata": {},
   "source": [
    "**Trying GradientBoosting Classifier for classifying first 5 movements of one exercise of one subject**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c468c89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_interpolated = interpolate_dataframe(x)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creating a model to classify 2 movements after interpolation\n",
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2)\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618faf6",
   "metadata": {},
   "source": [
    "**Trying PCA components with Random Forest Classifier for the first 5 movements of exercise 1 for subject 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95e3c9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_interpolated = interpolate_dataframe(x)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creating a model to classify 2 movements after interpolation\n",
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "pca = PCA(n_components=0.9)\n",
    "X_PCA = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_PCA, y,stratify=y, test_size=0.2)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75f576",
   "metadata": {},
   "source": [
    "# Fitting a model to classify all movements in exercise 1 for subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a7c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5520</th>\n",
       "      <th>5521</th>\n",
       "      <th>5522</th>\n",
       "      <th>5523</th>\n",
       "      <th>5524</th>\n",
       "      <th>5525</th>\n",
       "      <th>5526</th>\n",
       "      <th>5527</th>\n",
       "      <th>5528</th>\n",
       "      <th>5529</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.5981</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.4565</td>\n",
       "      <td>0.3906</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>1.1108</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>1.5991</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>1.3745</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3711</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 5531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8     \\\n",
       "0    0.0024  0.0098  0.3955  0.2783  0.0049  0.0366  0.5981  0.2075  0.4565   \n",
       "1    0.0098  0.0342  0.4639  0.3052  0.0024  0.0439  0.7568  0.1782  0.6079   \n",
       "2    0.0024  0.0073  1.1108  0.7227  0.0195  0.1025  1.5991  0.3369  0.9009   \n",
       "3    0.0024  0.0708  0.4639  0.2759  0.0098  0.0391  0.6567  0.2710  0.5713   \n",
       "4    0.0073  0.0024  0.3711  0.3979  0.0024  0.0122  0.4883  0.1489  0.4663   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "165  0.0659  0.0049  0.0122  0.1172  0.0049  0.0391  0.5713  0.5273  0.0122   \n",
       "166  0.0562  0.0024  0.0024  0.0024  0.0024  0.0122  0.1636  0.1147  0.0024   \n",
       "167  0.0391  0.0024  0.0049  0.0024  0.0024  0.0269  0.1245  0.2148  0.0024   \n",
       "168  0.0635  0.0024  0.0024  0.0024  0.0024  0.0024  0.1465  0.1025  0.0024   \n",
       "169  0.0732  0.0024  0.0024  0.0562  0.0024  0.0049  0.0464  0.1636  0.0024   \n",
       "\n",
       "       9     ...  5520  5521  5522  5523  5524  5525  5526  5527  5528  5529  \n",
       "0    0.3906  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1    0.5420  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2    1.3745  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3    0.7227  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4    0.4810  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "165  0.4712  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "166  0.0269  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "167  0.1147  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "168  0.0952  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "169  0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[170 rows x 5531 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_ex1 = load_data_DB1(subject=11, exercise=2)\n",
    "\n",
    "# Creating a list from range 1 to 12 because exercise 1 has 12 movements\n",
    "movements = list(range(1,18))\n",
    "\n",
    "# Add all repetitions of all movements to one dataframe\n",
    "sub1_ex1_df = pd.DataFrame()\n",
    "for m in movements:\n",
    "    sub1_ex1_df = sub1_ex1_df.append(get_full_repetitions(data=sub1_ex1,movement=m),ignore_index=True)\n",
    "\n",
    "sub1_ex1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b46ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5521</th>\n",
       "      <th>5522</th>\n",
       "      <th>5523</th>\n",
       "      <th>5524</th>\n",
       "      <th>5525</th>\n",
       "      <th>5526</th>\n",
       "      <th>5527</th>\n",
       "      <th>5528</th>\n",
       "      <th>5529</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.20265</td>\n",
       "      <td>0.39550</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.27830</td>\n",
       "      <td>0.14160</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.02075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.02195</td>\n",
       "      <td>0.04150</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.30270</td>\n",
       "      <td>0.30515</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>0.026067</td>\n",
       "      <td>0.03420</td>\n",
       "      <td>0.24905</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.38455</td>\n",
       "      <td>0.30520</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13305</td>\n",
       "      <td>0.21970</td>\n",
       "      <td>0.16845</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.30030</td>\n",
       "      <td>0.48340</td>\n",
       "      <td>0.29665</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.11080</td>\n",
       "      <td>0.72270</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.06100</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>1.5991</td>\n",
       "      <td>0.33690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63230</td>\n",
       "      <td>0.42480</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.07080</td>\n",
       "      <td>0.20265</td>\n",
       "      <td>0.33450</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.46390</td>\n",
       "      <td>0.27590</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>0.65670</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.57130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>1.08400</td>\n",
       "      <td>0.89840</td>\n",
       "      <td>0.03660</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>2.23880</td>\n",
       "      <td>0.42970</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>1.5063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.37110</td>\n",
       "      <td>0.39790</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00730</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.13550</td>\n",
       "      <td>0.26860</td>\n",
       "      <td>0.46390</td>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.00855</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.06105</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00730</td>\n",
       "      <td>0.20505</td>\n",
       "      <td>0.40280</td>\n",
       "      <td>0.31615</td>\n",
       "      <td>0.22950</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>0.08790</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00730</td>\n",
       "      <td>0.04025</td>\n",
       "      <td>0.07320</td>\n",
       "      <td>0.41990</td>\n",
       "      <td>0.29300</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.02690</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>0.16965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.03660</td>\n",
       "      <td>0.35890</td>\n",
       "      <td>0.25635</td>\n",
       "      <td>0.15380</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.032950</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.07445</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08540</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.02075</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>0.27590</td>\n",
       "      <td>0.26120</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.02930</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.02565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00610</td>\n",
       "      <td>0.00980</td>\n",
       "      <td>0.49320</td>\n",
       "      <td>0.32105</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.11230</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 5531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        3        4       5        6        7  \\\n",
       "0    0.0024  0.006100  0.009800  0.20265  0.39550  0.3369  0.27830  0.14160   \n",
       "1    0.0098  0.017933  0.026067  0.03420  0.24905  0.4639  0.38455  0.30520   \n",
       "2    0.0024  0.004850  0.007300  1.11080  0.72270  0.0195  0.06100  0.10250   \n",
       "3    0.0024  0.036600  0.070800  0.46390  0.27590  0.0098  0.03910  0.65670   \n",
       "4    0.0073  0.004850  0.002400  0.37110  0.39790  0.0024  0.00730  0.01220   \n",
       "..      ...       ...       ...      ...      ...     ...      ...      ...   \n",
       "165  0.0659  0.035400  0.004900  0.00855  0.01220  0.1172  0.06105  0.00490   \n",
       "166  0.0562  0.029300  0.002400  0.00240  0.00240  0.0024  0.01220  0.08790   \n",
       "167  0.0391  0.020750  0.002400  0.00490  0.00240  0.0024  0.00240  0.02690   \n",
       "168  0.0635  0.032950  0.002400  0.00240  0.00240  0.0024  0.00240  0.07445   \n",
       "169  0.0732  0.037800  0.002400  0.00240  0.00240  0.0562  0.02930  0.00240   \n",
       "\n",
       "          8        9  ...     5521     5522     5523     5524     5525  \\\n",
       "0    0.0049  0.02075  ...  0.00240  0.02195  0.04150  0.17210  0.30270   \n",
       "1    0.1538  0.00240  ...  0.13305  0.21970  0.16845  0.11720  0.30030   \n",
       "2    1.5991  0.33690  ...  0.63230  0.42480  0.00240  0.07080  0.20265   \n",
       "3    0.2710  0.57130  ...  0.17330  1.08400  0.89840  0.03660  0.13430   \n",
       "4    0.4883  0.14890  ...  0.14400  0.22460  0.00240  0.00240  0.13550   \n",
       "..      ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "165  0.0220  0.03910  ...  0.00240  0.00730  0.20505  0.40280  0.31615   \n",
       "166  0.1636  0.11470  ...  0.00490  0.00240  0.00730  0.04025  0.07320   \n",
       "167  0.1245  0.16965  ...  0.00240  0.00240  0.00240  0.03660  0.35890   \n",
       "168  0.1465  0.10250  ...  0.08540  0.00240  0.00240  0.02075  0.03910   \n",
       "169  0.0049  0.02565  ...  0.00240  0.00610  0.00980  0.49320  0.32105   \n",
       "\n",
       "        5526     5527    5528    5529  target  \n",
       "0    0.30515  0.30760  0.1611  0.0146       1  \n",
       "1    0.48340  0.29665  0.1099  0.1099       1  \n",
       "2    0.33450  0.16110  0.5273  0.1147       1  \n",
       "3    2.23880  0.42970  0.7935  1.5063       1  \n",
       "4    0.26860  0.46390  0.2417  0.2344       1  \n",
       "..       ...      ...     ...     ...     ...  \n",
       "165  0.22950  0.15140  0.1416  0.1318      17  \n",
       "166  0.41990  0.29300  0.0220  0.1440      17  \n",
       "167  0.25635  0.15380  0.0024  0.1294      17  \n",
       "168  0.27590  0.26120  0.0439  0.0073      17  \n",
       "169  0.14890  0.11230  0.2173  0.3223      17  \n",
       "\n",
       "[170 rows x 5531 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolating the dataframe so that there are no NaNs\n",
    "sub1_ex1_df_interpolated = interpolate_dataframe(sub1_ex1_df)\n",
    "sub1_ex1_df_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e49261ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4950</th>\n",
       "      <th>4951</th>\n",
       "      <th>4952</th>\n",
       "      <th>4953</th>\n",
       "      <th>4954</th>\n",
       "      <th>4955</th>\n",
       "      <th>4956</th>\n",
       "      <th>4957</th>\n",
       "      <th>4958</th>\n",
       "      <th>4959</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 4961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8     \\\n",
       "0    0.0366  0.0024  0.0024  0.0024  0.0049  0.0537  0.1318  0.0562  0.0293   \n",
       "1    0.0342  0.0024  0.0024  0.0024  0.0024  0.0146  0.2173  0.0415  0.0439   \n",
       "2    0.0513  0.0073  0.0024  0.0024  0.0024  0.0220  0.1318  0.0415  0.0513   \n",
       "3    0.0732  0.0073  0.0024  0.0024  0.0024  0.0024  0.2002  0.0757  0.0244   \n",
       "4    0.0293  0.0049  0.0024  0.0024  0.0024  0.0342  0.0586  0.0293  0.0269   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "165  0.0220  0.0024  0.0024  0.0122  0.0024  0.0854  0.4639  0.0757  0.0146   \n",
       "166  0.0366  0.0024  0.0024  0.0122  0.0073  0.0830  0.4053  0.0854  0.0073   \n",
       "167  0.0293  0.0024  0.0024  0.0024  0.0024  0.0806  0.3540  0.0732  0.0024   \n",
       "168  0.0342  0.0024  0.0098  0.0098  0.0024  0.0781  0.2759  0.1099  0.0098   \n",
       "169  0.0342  0.0024  0.0073  0.0415  0.0024  0.1343  0.6616  0.1221  0.0098   \n",
       "\n",
       "       9     ...  4950  4951  4952  4953  4954  4955  4956  4957  4958  4959  \n",
       "0    0.0146  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1    0.0220  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2    0.0342  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3    0.0684  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4    0.0171  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "..      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "165  0.3027  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "166  0.2295  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "167  0.2148  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "168  0.0977  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "169  0.2490  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[170 rows x 4961 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_ex1_df_no_missing = sub1_ex1_df.fillna(0)\n",
    "sub1_ex1_df_no_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1a99de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8372093 , 0.97674419, 0.95238095, 0.95238095])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = sub1_ex1_df_no_missing.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_no_missing[\"target\"]\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "cross_val_score(clf, X, y, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a3327f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds Cross Validation mean accuracy 0.5294117647058824\n",
      "Accuracy of training data 100.00 %\n",
      "Accuracy of test data 58.82 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = sub1_ex1_df_interpolated.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_interpolated[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "print(f\"5 folds Cross Validation mean accuracy {np.mean(cross_val_score(clf,X, y, cv=5))}\")\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy of training data {clf.score(X_train, y_train)*100 :.2f} %\")\n",
    "print(f\"Accuracy of test data {clf.score(X_test, y_test)*100 :.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54330f",
   "metadata": {},
   "source": [
    "**Trying KFold for random forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f7637f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds Cross Validation mean accuracy 0.2882352941176471\n",
      "Accuracy of training data 100.00 %\n",
      "Accuracy of test data 44.12 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = sub1_ex1_df_interpolated.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_interpolated[\"target\"]\n",
    "\n",
    "kf = KFold(shuffle=True,n_splits=5)\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "print(f\"5 folds Cross Validation mean accuracy {np.mean(cross_val_score(clf,X, y, cv=kf))}\")\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy of training data {clf.score(X_train, y_train)*100 :.2f} %\")\n",
    "print(f\"Accuracy of test data {clf.score(X_test, y_test)*100 :.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744336e",
   "metadata": {},
   "source": [
    "###### Fitting Linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f15967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds Cross Validation mean accuracy 0.15882352941176472\n",
      "Accuracy of training data 100.00 %\n",
      "Accuracy of test data 17.65 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "np.random.seed(200)\n",
    "\n",
    "X = sub1_ex1_df_interpolated.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_interpolated[\"target\"]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "linear_svc = LinearSVC()\n",
    "\n",
    "print(f\"5 folds Cross Validation mean accuracy {np.mean(cross_val_score(linear_svc,X, y, cv=kf))}\")\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "linear_svc = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy of training data {linear_svc.score(X_train, y_train)*100 :.2f} %\")\n",
    "print(f\"Accuracy of test data {linear_svc.score(X_test, y_test)*100 :.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ffea7",
   "metadata": {},
   "source": [
    "###### Fitting KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e886e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds Cross Validation mean accuracy 0.17594130675526026\n",
      "Accuracy of training data 19.69 %\n",
      "Accuracy of test data 18.60 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = sub1_ex1_df_interpolated.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_interpolated[\"target\"]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(f\"5 folds Cross Validation mean accuracy {np.mean(cross_val_score(knn,X, y, cv=4))}\")\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy of training data {knn.score(X_train, y_train)*100 :.2f} %\")\n",
    "print(f\"Accuracy of test data {knn.score(X_test, y_test)*100 :.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed3c21",
   "metadata": {},
   "source": [
    "###### Fitting Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c2839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds Cross Validation mean accuracy 0.19975083056478404\n",
      "Accuracy of training data 100.00 %\n",
      "Accuracy of test data 20.93 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = sub1_ex1_df_interpolated.drop(\"target\", axis=1)\n",
    "y = sub1_ex1_df_interpolated[\"target\"]\n",
    "\n",
    "log = LogisticRegression(max_iter=10000,penalty='l1',solver='liblinear')\n",
    "\n",
    "print(f\"5 folds Cross Validation mean accuracy {np.mean(cross_val_score(log,X, y, cv=4))}\")\n",
    "\n",
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)\n",
    "\n",
    "log = LogisticRegression(max_iter=10000,penalty='l1',solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy of training data {log.score(X_train, y_train)*100 :.2f} %\")\n",
    "print(f\"Accuracy of test data {log.score(X_test, y_test)*100 :.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80cef9",
   "metadata": {},
   "source": [
    "**Plotting to visualize effect before and after interpolation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e82452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting to visualize effect of interpolation\n",
    "\n",
    "idx = 169\n",
    "sig = sub1_ex1_df.iloc[idx].drop(\"target\").dropna()\n",
    "r1 = list(range(0, len(sig)))\n",
    "\n",
    "sig_interpolated = sub1_ex1_df_interpolated.iloc[idx].drop(\"target\")\n",
    "r2 = list(range(0, len(sig_interpolated)))\n",
    "\n",
    "# Plotting \n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n",
    "\n",
    "ax1.plot(r1,sig)\n",
    "ax2.plot(r2,sig_interpolated);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda4dce",
   "metadata": {},
   "source": [
    "## Trying Random Forest Classifier for each subject on exercise 1 using linear interpolation and calculate the avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a5cd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy for subject 1 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 1 for 10 random states is 0.31250000000000006\n",
      "Average Training Accuracy for subject 2 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 2 for 10 random states is 0.30416666666666664\n",
      "Average Training Accuracy for subject 3 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 3 for 10 random states is 0.3541666666666667\n",
      "Average Training Accuracy for subject 4 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 4 for 10 random states is 0.3458333333333333\n",
      "Average Training Accuracy for subject 5 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 5 for 10 random states is 0.4333333333333333\n",
      "Average Training Accuracy for subject 6 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 6 for 10 random states is 0.525\n",
      "Average Training Accuracy for subject 7 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 7 for 10 random states is 0.45\n",
      "Average Training Accuracy for subject 8 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 8 for 10 random states is 0.4083333333333333\n",
      "Average Training Accuracy for subject 9 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 9 for 10 random states is 0.4125\n",
      "Average Training Accuracy for subject 10 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 10 for 10 random states is 0.3\n",
      "Average Training Accuracy for subject 11 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 11 for 10 random states is 0.37083333333333335\n",
      "Average Training Accuracy for subject 12 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 12 for 10 random states is 0.5041666666666667\n",
      "Average Training Accuracy for subject 13 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 13 for 10 random states is 0.5625\n",
      "Average Training Accuracy for subject 14 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 14 for 10 random states is 0.2541666666666667\n",
      "Average Training Accuracy for subject 15 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 15 for 10 random states is 0.4416666666666667\n",
      "Average Training Accuracy for subject 16 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 16 for 10 random states is 0.3125\n",
      "Average Training Accuracy for subject 17 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 17 for 10 random states is 0.4\n",
      "Average Training Accuracy for subject 18 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 18 for 10 random states is 0.42499999999999993\n",
      "Average Training Accuracy for subject 19 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 19 for 10 random states is 0.4041666666666667\n",
      "Average Training Accuracy for subject 20 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 20 for 10 random states is 0.47916666666666663\n",
      "Average Training Accuracy for subject 21 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 21 for 10 random states is 0.5750000000000001\n",
      "Average Training Accuracy for subject 22 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 22 for 10 random states is 0.4125\n",
      "Average Training Accuracy for subject 23 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 23 for 10 random states is 0.5625\n",
      "Average Training Accuracy for subject 24 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 24 for 10 random states is 0.4458333333333333\n",
      "Average Training Accuracy for subject 25 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 25 for 10 random states is 0.5\n",
      "Average Training Accuracy for subject 26 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 26 for 10 random states is 0.4041666666666666\n",
      "Average Training Accuracy for subject 27 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 27 for 10 random states is 0.5291666666666666\n",
      "Average Training Accuracy for all subjects 1.0\n",
      "Average Test Accuracy for all subjects 0.4233024691358025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "training_acc_subjects = []\n",
    "test_acc_subjects = []\n",
    "\n",
    "random_states = [0,1,10,42,66,73,99,100,101,200]\n",
    "ex1_movements = list(range(1,13))\n",
    "\n",
    "# Iterate over 27 subjects of Database 1 and trying to classify exercise 1 \n",
    "for sub in list(range(1,28)):\n",
    "    \n",
    "    # Load the data \n",
    "    data = load_data_DB1(subject=sub, exercise=1)\n",
    "    \n",
    "    # Iterate over all movements and add them into a df\n",
    "    df = pd.DataFrame()\n",
    "    for m in ex1_movements:\n",
    "        df = df.append(get_full_repetitions(data=data, movement=m),ignore_index=True)\n",
    "    \n",
    "    # Interpolate the dataframe to fill NaN values using linear interpolation\n",
    "    df_interpolated = interpolate_dataframe(df)\n",
    "    \n",
    "    # Getting X & y\n",
    "    X = df_interpolated.drop(\"target\", axis=1)\n",
    "    y = df_interpolated[\"target\"]\n",
    "\n",
    "    # Getting imp features using PCA\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_transformed = pca.fit_transform(X)\n",
    "    \n",
    "    training_acc_states = []\n",
    "    test_acc_states = []\n",
    "    # Iterate over the 10 different random states to fit the model \n",
    "    for r in random_states:\n",
    "        \n",
    "        # Splitting the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, stratify=y, test_size=0.2, random_state=r)\n",
    "        clf = RandomForestClassifier(n_estimators=200)\n",
    "        \n",
    "        #Fitting the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        training_acc_states.append(clf.score(X_train, y_train))\n",
    "        test_acc_states.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    training_mean_states = np.mean(training_acc_states)\n",
    "    test_mean_states = np.mean(test_acc_states)\n",
    "    \n",
    "    print(f\"Average Training Accuracy for subject {sub} for 10 random states is {training_mean_states}\")\n",
    "    print(f\"Average Test Accuracy for subject {sub} for 10 random states is {test_mean_states}\")\n",
    "    training_acc_subjects.append(training_mean_states)\n",
    "    test_acc_subjects.append(test_mean_states)\n",
    "\n",
    "\n",
    "print(f\"Average Training Accuracy for all subjects {np.mean(training_acc_subjects)}\")\n",
    "print(f\"Average Test Accuracy for all subjects {np.mean(test_acc_subjects)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c8a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1       2       3       4       5       6       7       8     \\\n",
      "0     0.2759  0.2148  0.0317  0.0684  0.0049  0.0024  0.0024  0.1050  0.0928   \n",
      "1     0.2344  0.2026  0.1636  0.0610  0.0024  0.0024  0.0049  0.0391  0.5737   \n",
      "2     0.2197  0.1489  0.3638  0.1099  0.0024  0.0024  0.0024  0.0415  0.4688   \n",
      "3     0.2393  0.4688  0.3394  0.0464  0.0024  0.0024  0.0024  0.0928  0.4419   \n",
      "4     0.0171  0.0928  0.2124  0.0659  0.0024  0.0049  0.0024  0.0024  0.5444   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "3115  0.2075  0.0513  0.0049  0.0024  0.0049  0.0024  0.0049  0.2368  0.0024   \n",
      "3116  0.0537  0.0024  0.0049  0.0024  0.0049  0.0049  0.0049  0.1953  0.0049   \n",
      "3117  0.0391  0.0146  0.0073  0.0024  0.0024  0.0024  0.0049  0.1514  0.0049   \n",
      "3118  0.2246  0.0024  0.0049  0.0049  0.0049  0.0024  0.0049  0.3418  0.0024   \n",
      "3119  0.2271  0.0195  0.0317  0.0098  0.0049  0.0024  0.0049  0.2466  0.0122   \n",
      "\n",
      "        9     ...  5990  5991  5992  5993  5994  5995  5996  5997  5998  5999  \n",
      "0     0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "1     0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2     0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3     0.0317  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4     0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "...      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3115  0.0146  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3116  0.0391  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3117  0.0879  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3118  0.0708  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3119  0.0562  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[3120 rows x 6001 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "training_acc_subjects = []\n",
    "test_acc_subjects = []\n",
    "\n",
    "random_states = [0,1,10,42,66,73,99,100,101,200]\n",
    "ex1_movements = list(range(1,13))\n",
    "\n",
    "# Iterate over 27 subjects of Database 1 and trying to classify exercise 1 \n",
    "for sub in list(range(1,28)):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    # Load the data for all subjects except 1 to do leave-one out classification\n",
    "    for s in list(range(1,28)):\n",
    "        if s != sub:\n",
    "            data = load_data_DB1(subject=s, exercise=1)\n",
    "            # Iterate over all movements and add them into a df\n",
    "            for m in ex1_movements:\n",
    "                df = df.append(get_full_repetitions(data=data, movement=m),ignore_index=True)\n",
    "    print(df)\n",
    "    break\n",
    "    \n",
    "    \n",
    " \n",
    "#     # Interpolate the dataframe to fill NaN values using linear interpolation\n",
    "#     df_interpolated = interpolate_dataframe(df)\n",
    "    \n",
    "#     # Getting X & y\n",
    "#     X = df_interpolated.drop(\"target\", axis=1)\n",
    "#     y = df_interpolated[\"target\"]\n",
    "\n",
    "#     # Getting imp features using PCA\n",
    "#     pca = PCA(n_components=0.95)\n",
    "#     X_transformed = pca.fit_transform(X)\n",
    "    \n",
    "#     training_acc_states = []\n",
    "#     test_acc_states = []\n",
    "#     # Iterate over the 10 different random states to fit the model \n",
    "#     for r in random_states:\n",
    "        \n",
    "#         # Splitting the data\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, stratify=y, test_size=0.2, random_state=r)\n",
    "#         clf = RandomForestClassifier(n_estimators=200)\n",
    "        \n",
    "#         #Fitting the model\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         training_acc_states.append(clf.score(X_train, y_train))\n",
    "#         test_acc_states.append(clf.score(X_test, y_test))\n",
    "    \n",
    "#     training_mean_states = np.mean(training_acc_states)\n",
    "#     test_mean_states = np.mean(test_acc_states)\n",
    "    \n",
    "#     print(f\"Average Training Accuracy for subject {sub} for 10 random states is {training_mean_states}\")\n",
    "#     print(f\"Average Test Accuracy for subject {sub} for 10 random states is {test_mean_states}\")\n",
    "#     training_acc_subjects.append(training_mean_states)\n",
    "#     test_acc_subjects.append(test_mean_states)\n",
    "\n",
    "\n",
    "# print(f\"Average Training Accuracy for all subjects {np.mean(training_acc_subjects)}\")\n",
    "# print(f\"Average Test Accuracy for all subjects {np.mean(test_acc_subjects)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf7ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolated = interpolate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b4616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     260\n",
       "4     260\n",
       "6     260\n",
       "8     260\n",
       "10    260\n",
       "12    260\n",
       "1     260\n",
       "3     260\n",
       "5     260\n",
       "7     260\n",
       "9     260\n",
       "11    260\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525da0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5250</th>\n",
       "      <th>5251</th>\n",
       "      <th>5252</th>\n",
       "      <th>5253</th>\n",
       "      <th>5254</th>\n",
       "      <th>5255</th>\n",
       "      <th>5256</th>\n",
       "      <th>5257</th>\n",
       "      <th>5258</th>\n",
       "      <th>5259</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 5261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8     \\\n",
       "0    0.0171  0.0073  0.0024  0.0024  0.0024  0.0024  0.0757  0.0317  0.0024   \n",
       "1    0.0488  0.0073  0.0024  0.0024  0.0024  0.0024  0.0171  0.0488  0.0024   \n",
       "2    0.0073  0.0073  0.0024  0.0024  0.0024  0.0024  0.0269  0.0391  0.0024   \n",
       "3    0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0659  0.0342  0.0024   \n",
       "4    0.0024  0.0024  0.0024  0.0049  0.0024  0.0024  0.0098  0.0244  0.0049   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "115  0.0073  0.0024  0.0024  0.0024  0.0024  0.0024  0.0977  0.0903  0.0024   \n",
       "116  0.0073  0.0024  0.0024  0.0024  0.0024  0.0049  0.0342  0.0757  0.0024   \n",
       "117  0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0439  0.0024   \n",
       "118  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0586  0.0098   \n",
       "119  0.0024  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.1172  0.0024   \n",
       "\n",
       "       9     ...  5250  5251  5252  5253  5254  5255  5256  5257  5258  5259  \n",
       "0    0.0146  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1    0.0049  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2    0.0049  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3    0.0098  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4    0.0024  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "115  0.0366  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "116  0.0098  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "117  0.0122  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "118  0.0269  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "119  0.0366  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[120 rows x 5261 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get X_test and y_test from subject 1\n",
    "sub1 = load_data_DB1(subject=1, exercise=1)\n",
    "\n",
    "sub1_df = pd.DataFrame()\n",
    "for m in ex1_movements:\n",
    "                sub1_df = sub1_df.append(get_full_repetitions(data=sub1, movement=m),ignore_index=True)\n",
    "\n",
    "sub1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "870adf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_transformed = pca.fit_transform(X)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d805b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.090350</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.028050</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.028050</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.052450</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.026850</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.01705</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.039050</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.054950</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.01710</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00610</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.04885</td>\n",
       "      <td>0.05860</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04390</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.056967</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.032950</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00975</td>\n",
       "      <td>0.01710</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09280</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.02690</td>\n",
       "      <td>0.02690</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.02315</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.05860</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03415</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 6001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3        4       5       6       7  \\\n",
       "0    0.0171  0.012200  0.007300  0.004850  0.00240  0.0024  0.0024  0.0024   \n",
       "1    0.0488  0.028050  0.007300  0.004850  0.00240  0.0024  0.0024  0.0024   \n",
       "2    0.0073  0.007300  0.007300  0.004850  0.00240  0.0024  0.0024  0.0024   \n",
       "3    0.0049  0.003650  0.002400  0.002400  0.00240  0.0024  0.0024  0.0024   \n",
       "4    0.0024  0.002400  0.002400  0.002400  0.00365  0.0049  0.0024  0.0024   \n",
       "..      ...       ...       ...       ...      ...     ...     ...     ...   \n",
       "115  0.0073  0.005667  0.004033  0.002400  0.00240  0.0024  0.0024  0.0024   \n",
       "116  0.0073  0.006075  0.004850  0.003625  0.00240  0.0024  0.0024  0.0024   \n",
       "117  0.0049  0.003650  0.002400  0.002400  0.00240  0.0024  0.0024  0.0024   \n",
       "118  0.0024  0.002400  0.002400  0.002400  0.00240  0.0024  0.0024  0.0024   \n",
       "119  0.0024  0.007300  0.012200  0.007300  0.00240  0.0024  0.0024  0.0024   \n",
       "\n",
       "           8       9  ...     5991      5992      5993      5994      5995  \\\n",
       "0    0.00240  0.0024  ...  0.00240  0.064700  0.127000  0.090350  0.053700   \n",
       "1    0.00240  0.0024  ...  0.00240  0.002400  0.052450  0.102500  0.051300   \n",
       "2    0.00240  0.0024  ...  0.00240  0.002400  0.006100  0.009800  0.019500   \n",
       "3    0.00240  0.0024  ...  0.00240  0.002400  0.039050  0.075700  0.054950   \n",
       "4    0.00610  0.0098  ...  0.00240  0.002400  0.002400  0.002400  0.070800   \n",
       "..       ...     ...  ...      ...       ...       ...       ...       ...   \n",
       "115  0.00240  0.0024  ...  0.04390  0.050433  0.056967  0.063500  0.032950   \n",
       "116  0.00240  0.0024  ...  0.09280  0.062667  0.032533  0.002400  0.010567   \n",
       "117  0.02315  0.0439  ...  0.00240  0.002400  0.002400  0.002400  0.002400   \n",
       "118  0.00240  0.0024  ...  0.03415  0.065900  0.044733  0.023567  0.002400   \n",
       "119  0.00240  0.0024  ...  0.00240  0.002400  0.002400  0.019500  0.036600   \n",
       "\n",
       "         5996     5997     5998    5999  target  \n",
       "0    0.028050  0.00240  0.01465  0.0269       1  \n",
       "1    0.026850  0.00240  0.01340  0.0244       1  \n",
       "2    0.010950  0.00240  0.01705  0.0317       1  \n",
       "3    0.034200  0.01710  0.01100  0.0049       1  \n",
       "4    0.039100  0.04885  0.05860  0.0220       1  \n",
       "..        ...      ...      ...     ...     ...  \n",
       "115  0.002400  0.00975  0.01710  0.0171      12  \n",
       "116  0.018733  0.02690  0.02690  0.0269      12  \n",
       "117  0.002400  0.05860  0.00240  0.0195      12  \n",
       "118  0.002400  0.00240  0.00240  0.0024      12  \n",
       "119  0.019500  0.00240  0.00850  0.0146      12  \n",
       "\n",
       "[120 rows x 6001 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_df_interpolated = interpolate_dataframe_with_length(sub1_df, X.shape[1])\n",
    "sub1_df_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc7392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sub1_df_interpolated.drop(\"target\", axis=1)\n",
    "y_test = sub1_df_interpolated[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b9eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_interpolated.drop(\"target\", axis=1)\n",
    "y = df_interpolated[\"target\"]\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_transformed = pca.fit_transform(X)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e9063c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613807e",
   "metadata": {},
   "source": [
    "## Trying Random Forest Classifier for each subject on exercise 1 by dropping all columns that do not have values for all rows and calculate the avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49490555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "training_acc_subjects = []\n",
    "test_acc_subjects = []\n",
    "\n",
    "random_states = [0,1,10,42,66,73,99,100,101,200]\n",
    "ex1_movements = list(range(1,13))\n",
    "\n",
    "# Iterate over 27 subjects of Database 1 and trying to classify exercise 1 \n",
    "for sub in list(range(1,28)):\n",
    "    \n",
    "    # Load the data \n",
    "    data = load_data_DB1(subject=sub, exercise=1)\n",
    "    \n",
    "    # Iterate over all movements and add them into a df\n",
    "    df = pd.DataFrame()\n",
    "    for m in ex1_movements:\n",
    "        df = df.append(get_full_repetitions(data=data, movement=m),ignore_index=True)\n",
    "    \n",
    "    # Interpolate the dataframe to fill NaN values using linear interpolation\n",
    "    df = df.dropna(axis=1)\n",
    "    \n",
    "    # Getting X & y\n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df[\"target\"]\n",
    "\n",
    "\n",
    "    training_acc_states = []\n",
    "    test_acc_states = []\n",
    "    # Iterate over the 10 different random states to fit the model \n",
    "    for r in random_states:\n",
    "        \n",
    "        # Splitting the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=r)\n",
    "        clf = RandomForestClassifier(n_estimators=200)\n",
    "        \n",
    "        #Fitting the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        training_acc_states.append(clf.score(X_train, y_train))\n",
    "        test_acc_states.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    training_mean_states = np.mean(training_acc_states)\n",
    "    test_mean_states = np.mean(test_acc_states)\n",
    "    \n",
    "    print(f\"Average Training Accuracy for subject {sub} for 10 random states is {training_mean_states}\")\n",
    "    print(f\"Average Test Accuracy for subject {sub} for 10 random states is {test_mean_states}\")\n",
    "    training_acc_subjects.append(training_mean_states)\n",
    "    test_acc_subjects.append(test_mean_states)\n",
    "\n",
    "\n",
    "print(f\"Average Training Accuracy for all subjects {np.mean(training_acc_subjects)}\")\n",
    "print(f\"Average Test Accuracy for all subjects {np.mean(test_acc_subjects)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87e5ce",
   "metadata": {},
   "source": [
    "## Trying LinearSVM Classifier for each subject on exercise 1 using linear interpolation and calculate the avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a4c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy for subject 1 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 1 for 10 random states is 0.1375\n",
      "Average Training Accuracy for subject 2 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 2 for 10 random states is 0.19166666666666668\n",
      "Average Training Accuracy for subject 3 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 3 for 10 random states is 0.14583333333333331\n",
      "Average Training Accuracy for subject 4 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 4 for 10 random states is 0.19583333333333333\n",
      "Average Training Accuracy for subject 5 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 5 for 10 random states is 0.22916666666666669\n",
      "Average Training Accuracy for subject 6 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 6 for 10 random states is 0.22083333333333335\n",
      "Average Training Accuracy for subject 7 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 7 for 10 random states is 0.14166666666666666\n",
      "Average Training Accuracy for subject 8 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 8 for 10 random states is 0.1\n",
      "Average Training Accuracy for subject 9 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 9 for 10 random states is 0.1125\n",
      "Average Training Accuracy for subject 10 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 10 for 10 random states is 0.2041666666666667\n",
      "Average Training Accuracy for subject 11 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 11 for 10 random states is 0.14583333333333334\n",
      "Average Training Accuracy for subject 12 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 12 for 10 random states is 0.25\n",
      "Average Training Accuracy for subject 13 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 13 for 10 random states is 0.1875\n",
      "Average Training Accuracy for subject 14 for 10 random states is 1.0\n",
      "Average Test Accuracy for subject 14 for 10 random states is 0.2583333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1002b07b9dfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Interpolate the dataframe to fill NaN values using linear interpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdf_interpolated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpolate_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Getting X & y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5ea0ac4b7d07>\u001b[0m in \u001b[0;36minterpolate_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_row_length\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcurrent_row_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mnew_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mnew_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3460\u001b[0m             \u001b[0mProvide\u001b[0m \u001b[0mis_copy\u001b[0m \u001b[0mchecks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3461\u001b[0m         \"\"\"\n\u001b[1;32m-> 3462\u001b[1;33m         \u001b[0mcacher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cacher\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3464\u001b[0m             \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5455\u001b[0m         \u001b[1;31m# calling obj.__getattr__('x').\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5456\u001b[0m         if (\n\u001b[1;32m-> 5457\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5458\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5459\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "training_acc_subjects = []\n",
    "test_acc_subjects = []\n",
    "\n",
    "random_states = [0,1,10,42,66,73,99,100,101,200]\n",
    "ex1_movements = list(range(1,13))\n",
    "\n",
    "# Iterate over 27 subjects of Database 1 and trying to classify exercise 1 \n",
    "for sub in list(range(1,28)):\n",
    "    \n",
    "    # Load the data \n",
    "    data = load_data_DB1(subject=sub, exercise=1)\n",
    "    \n",
    "    # Iterate over all movements and add them into a df\n",
    "    df = pd.DataFrame()\n",
    "    for m in ex1_movements:\n",
    "        df = df.append(get_full_repetitions(data=data, movement=m),ignore_index=True)\n",
    "    \n",
    "    # Interpolate the dataframe to fill NaN values using linear interpolation\n",
    "    df_interpolated = interpolate_dataframe(df)\n",
    "    \n",
    "    # Getting X & y\n",
    "    X = df_interpolated.drop(\"target\", axis=1)\n",
    "    y = df_interpolated[\"target\"]\n",
    "\n",
    "\n",
    "\n",
    "    training_acc_states = []\n",
    "    test_acc_states = []\n",
    "    # Iterate over the 10 different random states to fit the model \n",
    "    for r in random_states:\n",
    "        \n",
    "        # Splitting the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=r)\n",
    "        linear_svm = LinearSVC(C=0.7)\n",
    "        \n",
    "        #Fitting the model\n",
    "        linear_svm.fit(X_train, y_train)\n",
    "        training_acc_states.append(linear_svm.score(X_train, y_train))\n",
    "        test_acc_states.append(linear_svm.score(X_test, y_test))\n",
    "    \n",
    "    training_mean_states = np.mean(training_acc_states)\n",
    "    test_mean_states = np.mean(test_acc_states)\n",
    "    \n",
    "    print(f\"Average Training Accuracy for subject {sub} for 10 random states is {training_mean_states}\")\n",
    "    print(f\"Average Test Accuracy for subject {sub} for 10 random states is {test_mean_states}\")\n",
    "    training_acc_subjects.append(training_mean_states)\n",
    "    test_acc_subjects.append(test_mean_states)\n",
    "\n",
    "\n",
    "print(f\"Average Training Accuracy for all subjects {np.mean(training_acc_subjects)}\")\n",
    "print(f\"Average Test Accuracy for all subjects {np.mean(test_acc_subjects)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109021d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
